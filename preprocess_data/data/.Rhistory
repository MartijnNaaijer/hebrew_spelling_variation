one_mh_iteration <- function(w, current){
# STEP 1: Propose the next chain location
proposal <- runif(1, min = current - w, max = current + w)
# STEP 2: Decide whether or not to go there
proposal_plaus <- dnorm(proposal, 0, 1) * dnorm(6.25, proposal, 0.75)
current_plaus  <- dnorm(current, 0, 1) * dnorm(6.25, current, 0.75)
alpha <- min(1, proposal_plaus / current_plaus)
next_stop <- sample(c(proposal, current),
size = 1, prob = c(alpha, 1-alpha))
# Return the results
return(data.frame(proposal, alpha, next_stop))
}
mh_tour <- function(N, w){
# 1. Start the chain at location 3
current <- 3
# 2. Initialize the simulation
mu <- rep(0, N)
# 3. Simulate N Markov chain stops
for(i in 1:N){
# Simulate one iteration
sim <- one_mh_iteration(w = w, current = current)
# Record next location
mu[i] <- sim$next_stop
# Reset the current location
current <- sim$next_stop
}
# 4. Return the chain locations
return(data.frame(iteration = c(1:N), mu))
}
ggplot(mh_simulation_1, aes(x = iteration, y = mu)) +
geom_line()
library(tidyverse)
ggplot(mh_simulation_1, aes(x = iteration, y = mu)) +
geom_line()
set.seed(84735)
mh_simulation_1 <- mh_tour(N = 5000, w = 1)
ggplot(mh_simulation_1, aes(x = iteration, y = mu)) +
geom_line()
ggplot(mh_simulation_1, aes(x = mu)) +
geom_histogram(aes(y = ..density..), color = "white", bins = 20) +
stat_function(fun = dnorm, args = list(4,0.6), color = "blue")
mh_tour <- function(N, w){
# 1. Start the chain at location 3
current <- 4
# 2. Initialize the simulation
mu <- rep(0, N)
# 3. Simulate N Markov chain stops
for(i in 1:N){
# Simulate one iteration
sim <- one_mh_iteration(w = w, current = current)
# Record next location
mu[i] <- sim$next_stop
# Reset the current location
current <- sim$next_stop
}
# 4. Return the chain locations
return(data.frame(iteration = c(1:N), mu))
}
set.seed(84735)
mh_simulation_1 <- mh_tour(N = 5000, w = 1)
ggplot(mh_simulation_1, aes(x = iteration, y = mu)) +
geom_line()
ggplot(mh_simulation_1, aes(x = mu)) +
geom_histogram(aes(y = ..density..), color = "white", bins = 20) +
stat_function(fun = dnorm, args = list(4,0.6), color = "blue")
one_mh_iteration <- function(w, current){
# STEP 1: Propose the next chain location
proposal <- runif(1, min = current - w, max = current + w)
# STEP 2: Decide whether or not to go there
proposal_plaus <- dnorm(proposal, 0, 1) * dnorm(6.25, proposal, 0.75)
current_plaus  <- dnorm(current, 0, 1) * dnorm(6.25, current, 0.75)
alpha <- min(1, proposal_plaus / current_plaus)
next_stop <- sample(c(proposal, current),
size = 1, prob = c(alpha, 1-alpha))
# Return the results
return(data.frame(proposal, alpha, next_stop))
}
mh_tour <- function(N, w){
# 1. Start the chain at location 3
current <- 10
# 2. Initialize the simulation
mu <- rep(0, N)
# 3. Simulate N Markov chain stops
for(i in 1:N){
# Simulate one iteration
sim <- one_mh_iteration(w = w, current = current)
# Record next location
mu[i] <- sim$next_stop
# Reset the current location
current <- sim$next_stop
}
# 4. Return the chain locations
return(data.frame(iteration = c(1:N), mu))
}
set.seed(84735)
mh_simulation_1 <- mh_tour(N = 5000, w = 1)
ggplot(mh_simulation_1, aes(x = iteration, y = mu)) +
geom_line()
ggplot(mh_simulation_1, aes(x = mu)) +
geom_histogram(aes(y = ..density..), color = "white", bins = 20) +
stat_function(fun = dnorm, args = list(4,0.6), color = "blue")
one_mh_iteration <- function(w, current){
# STEP 1: Propose the next chain location
proposal <- runif(1, min = current - w, max = current + w)
# STEP 2: Decide whether or not to go there
proposal_plaus <- dnorm(proposal, 0, 1) * dnorm(10, proposal, 0.75)
current_plaus  <- dnorm(current, 0, 1) * dnorm(10, current, 0.75)
alpha <- min(1, proposal_plaus / current_plaus)
next_stop <- sample(c(proposal, current),
size = 1, prob = c(alpha, 1-alpha))
# Return the results
return(data.frame(proposal, alpha, next_stop))
}
mh_tour <- function(N, w){
# 1. Start the chain at location 3
current <- 3
# 2. Initialize the simulation
mu <- rep(0, N)
# 3. Simulate N Markov chain stops
for(i in 1:N){
# Simulate one iteration
sim <- one_mh_iteration(w = w, current = current)
# Record next location
mu[i] <- sim$next_stop
# Reset the current location
current <- sim$next_stop
}
# 4. Return the chain locations
return(data.frame(iteration = c(1:N), mu))
}
set.seed(84735)
mh_simulation_1 <- mh_tour(N = 5000, w = 1)
ggplot(mh_simulation_1, aes(x = iteration, y = mu)) +
geom_line()
ggplot(mh_simulation_1, aes(x = mu)) +
geom_histogram(aes(y = ..density..), color = "white", bins = 20) +
stat_function(fun = dnorm, args = list(4,0.6), color = "blue")
suff_model <- "C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/matres_isaiah/prepare_matres/data/models_r/model_all_scrolls_complete_pre_suff_qsp_phase_no_lextype.rda"
model_old = readRDS(suff_model)
summary(model_old)
library(bayesrules)
library(tidyverse)
library(bayesplot)
library(rstan)
library(rstanarm)
library(tidybayes)
library(broom.mixed)
library(janitor)
library(tidybayes)
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
ebh_books <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy", "Joshua",
"Judges", "1_Samuel", "2_Samuel", "1_Kings", "2_Kings")
lbh_books <- c("Esther", "Daniel", "Ezra", "Nehemiah", "1_Chronicles", "2_Chronicles")
QSP_SCROLLS = c('2Q3', '4Q13', '4Q20', '2Q7', '4Q27', '1Q4', '2Q12', '4Q37', '4Q38', '4Q38a', '4Q40', '4Q53',
'1Qisaa', '4Q57', '2Q13', '4Q78', '4Q80', '4Q82', '4Q128', '4Q129', '4Q134', '4Q135', '4Q136',
'4Q137', '4Q138', '4Q139', '4Q140', '4Q141', '4Q142', '4Q143', '4Q144', '4Q158', '4Q364',
'4Q365', '4Q96', '4Q111', '4Q109', '11Q5', '11Q6', '11Q7', '11Q8')
length(QSP_SCROLLS)
setwd('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/preprocess_data/data')
dat <- read.csv('nouns_adjectives.csv', sep='\t')
dim(dat)
head(dat)
str(dat)
unique(dat$scroll)
unique(dat$book)
selected_books <- c('Genesis', 'Exodus', 'Leviticus',
'Isaiah', 'Jonah', '2_Chronicles')
selected_scrolls <- c('MT', '1Q8', '1QisaaI', '1QisaaII')
dat$has_vowel_letter <- as.factor(dat$has_vowel_letter)
dat$has_prefix <- as.factor(dat$has_prefix)
dat$has_pronominal_suffix <- as.factor(dat$has_pronominal_suffix)
dat$has_nme <- as.factor(dat$has_nme)
#dat$has_suffix <- dat$has_nme == 1 | dat$has_pronominal_suffix == 1 | dat$has_hloc == 1
#dat$has_suffix <- as.factor(dat$has_suffix)
dat$lex <- as.factor(dat$lex)
dat$book <- as.factor(dat$book)
dat$qsp <- as.factor(dat$qsp)
table(dat$qsp)
table(dat_qsp$qsp, dat_qsp$scroll)
dat$book <- as.factor(dat$book)
dat$type <- as.factor(dat$type)
dat$lex_type <- paste(dat$lex, dat$type, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
dat$phase <- ifelse(dat$book %in% ebh_books, 'EBH', ifelse(dat$book %in% lbh_books, 'LBH', 'NO'))
dat$qsp <- ifelse(dat$scroll %in% QSP_SCROLLS, 1, 0)
dat_qsp <- dat %>% filter(qsp == 1)
dat$qsp <- ifelse(dat$scroll %in% QSP_SCROLLS, 1, 0)
# Make 2 scrolls of 1Qisaa
dat$scroll <- ifelse(dat$scroll == '1Qisaa' & dat$chapter < 34, '1QisaaI',
ifelse(dat$scroll == '1Qisaa' & dat$chapter > 33, '1QisaaII',
dat$scroll))
dat$scroll <- as.factor(dat$scroll)
head(dat)
tail(dat)
table(dat$scroll)
table(dat$scroll, dat$book)
# Make 2 scrolls of 1Qisaa
dat$scroll <- ifelse(dat$scroll == '1Qisaa' & dat$chapter < 34, '1QisaaI',
ifelse(dat$scroll == '1Qisaa' & dat$chapter > 33, '1QisaaII',
dat$scroll))
dat$scroll <- as.factor(dat$scroll)
head(dat)
tail(dat)
table(dat$scroll)
table(dat$scroll, dat$book)
unique(dat$lex)
str(dat)
mt_sel <- dat #%>%
mt_sel <- dat %>%
filter(book %in% selected_books) %>%
filter(scroll %in% selected_scrolls)
dim(mt_sel)
unique(dat$lex)
str(dat)
mt_sel <- dat %>%
filter(book %in% selected_books) %>%
filter(scroll %in% selected_scrolls)
dim(mt_sel)
setwd('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/preprocess_data/data')
dat <- read.csv('nouns_adjectives.csv', sep='\t')
dim(dat)
head(dat)
str(dat)
unique(dat$scroll)
unique(dat$book)
selected_books <- c('Genesis', 'Exodus', 'Leviticus',
'Isaiah', 'Jonah', '2_Chronicles')
selected_scrolls <- c('MT', '1Q8', '1QisaaI', '1QisaaII')
dat$has_vowel_letter <- as.factor(dat$has_vowel_letter)
dat$has_prefix <- as.factor(dat$has_prefix)
dat$has_pronominal_suffix <- as.factor(dat$has_pronominal_suffix)
dat$has_nme <- as.factor(dat$has_nme)
#dat$has_suffix <- dat$has_nme == 1 | dat$has_pronominal_suffix == 1 | dat$has_hloc == 1
#dat$has_suffix <- as.factor(dat$has_suffix)
dat$lex <- as.factor(dat$lex)
dat$book <- as.factor(dat$book)
dat$type <- as.factor(dat$type)
dat$lex_type <- paste(dat$lex, dat$type, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
dat$phase <- ifelse(dat$book %in% ebh_books, 'EBH', ifelse(dat$book %in% lbh_books, 'LBH', 'NO'))
dat$qsp <- ifelse(dat$scroll %in% QSP_SCROLLS, 1, 0)
# Make 2 scrolls of 1Qisaa
dat$scroll <- ifelse(dat$scroll == '1Qisaa' & dat$chapter < 34, '1QisaaI',
ifelse(dat$scroll == '1Qisaa' & dat$chapter > 33, '1QisaaII',
dat$scroll))
dat$scroll <- as.factor(dat$scroll)
head(dat)
tail(dat)
table(dat$scroll)
table(dat$scroll, dat$book)
unique(dat$lex)
str(dat)
dim(dat)
mt_sel <- dat %>%
filter(book %in% selected_books) %>%
filter(scroll %in% selected_scrolls)
dim(mt_sel)
table(mt_sel$book)
table(mt_sel$book, mt_sel$lex)
table(mt_sel$scroll)
table(mt_sel$lex, mt_sel$has_vowel_letter)
dim(mt_sel)
head(mt_sel)
mt_sel_df
head(mt_sel)
table(mt_sel$has_vowel_letter)
heb_model_no_random <- stan_glm(
has_vowel_letter ~  has_nme + has_pronominal_suffix + has_prefix + (has_nme + has_pronominal_suffix + has_prefix | scroll/book/lex_type),
data = mt_sel, family = binomial,
prior_intercept = normal(0, 1.0, autoscale = TRUE),
prior = normal(0, 1.0, autoscale = TRUE),
prior_covariance = decov(reg=1, conc=1, shape=1, scale=1),
chains = 4, iter = 4000, seed = 84735, adapt_delta=0.9
)
heb_model_no_random <- stan_glmer(
has_vowel_letter ~  has_nme + has_pronominal_suffix + has_prefix + (has_nme + has_pronominal_suffix + has_prefix | scroll/book/lex_type),
data = mt_sel, family = binomial,
prior_intercept = normal(0, 1.0, autoscale = TRUE),
prior = normal(0, 1.0, autoscale = TRUE),
prior_covariance = decov(reg=1, conc=1, shape=1, scale=1),
chains = 4, iter = 4000, seed = 84735, adapt_delta=0.9
)
heb_model_no_random <- stan_glm(
has_vowel_letter ~  has_nme + has_pronominal_suffix + has_prefix, # + (has_nme + has_pronominal_suffix + has_prefix | scroll/book/lex_type),
data = mt_sel, family = binomial,
prior_intercept = normal(0, 1.0, autoscale = TRUE),
prior = normal(0, 1.0, autoscale = TRUE),
prior_covariance = decov(reg=1, conc=1, shape=1, scale=1),
chains = 4, iter = 4000, seed = 84735, adapt_delta=0.9
)
heb_model_no_random <- stan_glm(
has_vowel_letter ~  has_nme, # + has_pronominal_suffix + has_prefix, # + (has_nme + has_pronominal_suffix + has_prefix | scroll/book/lex_type),
data = mt_sel, family = binomial,
prior_intercept = normal(0, 1.0, autoscale = TRUE),
prior = normal(0, 1.0, autoscale = TRUE),
prior_covariance = decov(reg=1, conc=1, shape=1, scale=1),
chains = 4, iter = 4000, seed = 84735, adapt_delta=0.9
)
heb_model_no_random <- stan_glmer(
has_vowel_letter ~  has_nme + has_pronominal_suffix + has_prefix + (has_nme + has_pronominal_suffix + has_prefix | scroll/book/lex_type),
data = mt_sel, family = binomial,
prior_intercept = normal(0, 1.0, autoscale = TRUE),
prior = normal(0, 1.0, autoscale = TRUE),
prior_covariance = decov(reg=1, conc=1, shape=1, scale=1),
chains = 4, iter = 4, seed = 84735, adapt_delta=0.9
)
setwd('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/preprocess_data/data')
dat <- read.csv('nouns_adjectives.csv', sep='\t')
dim(dat)
head(dat)
str(dat)
unique(dat$scroll)
unique(dat$book)
selected_books <- c('Genesis', # 'Exodus', 'Leviticus',
'Isaiah') # , 'Jonah', '2_Chronicles')
selected_scrolls <- c('MT', '1Q8', '1QisaaI', '1QisaaII')
dat$has_vowel_letter <- as.factor(dat$has_vowel_letter)
dat$has_prefix <- as.factor(dat$has_prefix)
dat$has_pronominal_suffix <- as.factor(dat$has_pronominal_suffix)
dat$has_nme <- as.factor(dat$has_nme)
#dat$has_suffix <- dat$has_nme == 1 | dat$has_pronominal_suffix == 1 | dat$has_hloc == 1
#dat$has_suffix <- as.factor(dat$has_suffix)
dat$lex <- as.factor(dat$lex)
dat$book <- as.factor(dat$book)
dat$type <- as.factor(dat$type)
dat$lex_type <- paste(dat$lex, dat$type, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
dat$phase <- ifelse(dat$book %in% ebh_books, 'EBH', ifelse(dat$book %in% lbh_books, 'LBH', 'NO'))
dat$qsp <- ifelse(dat$scroll %in% QSP_SCROLLS, 1, 0)
# Make 2 scrolls of 1Qisaa
dat$scroll <- ifelse(dat$scroll == '1Qisaa' & dat$chapter < 34, '1QisaaI',
ifelse(dat$scroll == '1Qisaa' & dat$chapter > 33, '1QisaaII',
dat$scroll))
dat$scroll <- as.factor(dat$scroll)
head(dat)
tail(dat)
table(dat$scroll)
table(dat$scroll, dat$book)
unique(dat$lex)
str(dat)
dim(dat)
mt_sel <- dat %>%
filter(book %in% selected_books) %>%
filter(scroll %in% selected_scrolls)
dim(mt_sel)
table(mt_sel$book)
table(mt_sel$book, mt_sel$lex)
table(mt_sel$scroll)
table(mt_sel$lex, mt_sel$has_vowel_letter)
dim(mt_sel)
head(mt_sel)
table(mt_sel$has_vowel_letter)
heb_model_no_random <- stan_glmer(
has_vowel_letter ~  has_nme + has_pronominal_suffix + has_prefix + (has_nme + has_pronominal_suffix + has_prefix | scroll/book/lex_type),
data = mt_sel, family = binomial,
prior_intercept = normal(0, 1.0, autoscale = TRUE),
prior = normal(0, 1.0, autoscale = TRUE),
prior_covariance = decov(reg=1, conc=1, shape=1, scale=1),
chains = 4, iter = 4, seed = 84735, adapt_delta=0.9
)
