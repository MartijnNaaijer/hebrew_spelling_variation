geom_bar(stat = "identity", color = "black", position = position_dodge()) +
labs(x = '', y = 'Fraction of full spelling') +
geom_errorbar( aes(x=book2, ymin=lower, ymax=upper), width=0.4, colour='black', alpha=0.9, size=1.3,
position = position_dodge(0.9)) +
theme_minimal() +
theme(text = element_text(size = 20)) +
theme(axis.text.x = element_text(angle = 45, hjust=1))
books <- unique(dat$book2)
hpd_fullness$book2 <- factor(hpd_fullness$book2, levels=books)
ggplot(data = hpd_fullness, aes(x = book2, y = mean)) +
geom_bar(stat = "identity", color = "black", position = position_dodge()) +
labs(x = '', y = 'Fraction of full spelling') +
geom_errorbar( aes(x=book2, ymin=lower, ymax=upper), width=0.4, colour='black', alpha=0.9, size=1.3,
position = position_dodge(0.9)) +
theme_minimal() +
theme(text = element_text(size = 20)) +
theme(axis.text.x = element_text(angle = 45, hjust=1))
ranef(bayes_model_mt_dss)
table(dat$vt)
dat |> filter(second_char != 'Y') |> filter(vt %in% c('ptca', 'ptcp'))
ptc <- dat |> filter(second_char != 'Y') |> filter(vt %in% c('ptca', 'ptcp'))
table(ptc$has_vowel_letter)
table(ptc$has_prefix, ptc$has_vowel_letter)
table(ptc$has_suffix, ptc$has_vowel_letter)
dat$section <- paste(dat$book, dat$chapter, dat$versesep='_')
dat$section <- paste(dat$book, dat$chapter, dat$verse, sep='_')
head(dat)
dat$section <- paste(dat$lex, dat$book, dat$chapter, dat$verse, sep='_')
head(dat)
dat$lex_section <- paste(dat$lex, dat$book, dat$chapter, dat$verse, sep='_')
head(dat)
unique(dat$lex_section)
lex_sections <- unique(dat$lex_section)
dat$lex_section <- paste(dat$lex, dat$book, dat$chapter, dat$verse, sep='_')
head(dat)
lex_sections <- unique(dat$lex_section)
for (lex_s in lex_sections) {
lex_section_df <- dat |> filter(lex_section == lex_s)
}
lex_sections <- unique(dat$lex_section)
for (lex_s in lex_sections) {
lex_section_df <- dat |> filter(lex_section == lex_s)
if (length(unique(lex_section_df$has_vowel_letter)) > 1) {
print(lex_section_df)
}
}
lex_sections <- unique(dat$lex_section)
for (lex_s in lex_sections) {
lex_section_df <- dat |> filter(lex_section == lex_s)
if (length(unique(lex_section_df$has_vowel_letter)) > 1) {
print(lex_section_df)
print('')
}
}
lex_sections <- unique(dat$lex_section)
for (lex_s in lex_sections) {
lex_section_df <- dat |> filter(lex_section == lex_s)
if (length(unique(lex_section_df$has_vowel_letter)) > 1 & length(unique(lex_section_df$scroll)) > 1) {
print(lex_section_df)
print('')
}
}
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
library(ggmcmc)
library(coda)
library(bayestestR) # p_direction
MODEL_FOLDER <- 'C:/Users/geitb/Kopenhagen/KopenhagenResearch/monograph/chapters/NounsAdjectives/models_rstanarm'
IMAGE_FOLDER <- 'C:/Users/geitb/Dropbox/monograph_orthography/nouns_adjectives/images_nouns_adjv'
EBH_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy", "Joshua",
"Judges", "1_Samuel", "2_Samuel", "1_Kings", "2_Kings")
LBH_BOOKS <- c("Esther", "Daniel", "Ezra", "Nehemiah", "1_Chronicles", "2_Chronicles")
LAW_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy")
QSP_SCROLLS <- c('1Qisaa', '1QisaaI', '1QisaaII','2Q3', '4Q13', '4Q20', '2Q7', '4Q27', '1Q4', '2Q12', '4Q37', '4Q38', '4Q38a', '4Q40', '4Q53',
'4Q57', '2Q13', '4Q78', '4Q80', '4Q82', '4Q128', '4Q129', '4Q134', '4Q135', '4Q136',
'4Q137', '4Q138', '4Q139', '4Q140', '4Q141', '4Q142', '4Q143', '4Q144', '4Q158', '4Q364',
'4Q365', '4Q96', '4Q111', '4Q109', '11Q5', '11Q6', '11Q7', '11Q8')
length(QSP_SCROLLS)
logit2prob <- function(logit){
odds <- exp(logit)
prob <- odds / (1 + odds)
return(prob)
}
logit2odds <- function(logit){
odds <- exp(logit)
return(odds)
}
text_sizes = theme(
plot.title = element_text(size = 20),
axis.title.x = element_text(size = 16),
axis.text.x = element_text(size = 14),
axis.title.y = element_blank(),
axis.text.y = element_text(size = 20))
dat <- read.csv('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/data/nouns_adjectives.csv', sep='\t')
dim(dat)
str(dat)
dat$has_suffix <- as.factor(as.numeric(dat$has_prs | dat$has_nme | dat$has_hloc))
# has_prefix, has_prs, has_nme, lex, book, has_vowel_letter
dat$has_prefix <- as.factor(dat$has_prefix)
dat$has_prs <- as.factor(dat$has_prs)
dat$has_nme <- as.factor(dat$has_nme)
dat$has_hloc <- as.factor(dat$has_hloc)
dat$lex <- as.factor(dat$lex)
dat$book <- as.factor(dat$book)
dat$has_vowel_letter <- as.factor(dat$has_vowel_letter)
dat$neigh_vowel_letter <- as.factor(dat$neigh_vowel_letter)
dat$type <- as.factor(dat$type)
dat$book2 <- dat$book %>% str_replace('1_', '') |> str_replace('2_', '')
table(dat$book2)
dat$book2 <- as.factor(dat$book2)
dat$phase <- ifelse(dat$book %in% EBH_BOOKS, 'EBH', ifelse(dat$book %in% LBH_BOOKS, 'LBH', 'NO'))
dat$law_phase <- ifelse(dat$book %in% LAW_BOOKS, 0, ifelse(dat$book %in% EBH_BOOKS, 1,
ifelse(dat$book %in% LBH_BOOKS, 2, 3)))
dat$law_phase <- as.factor(dat$law_phase)
dat$qsp <- ifelse(dat$scroll %in% QSP_SCROLLS, 1, 0)
# Make 2 scrolls of 1Qisaa
dat$scroll <- ifelse(dat$scroll == '1Qisaa' & dat$chapter < 34, '1QisaaI',
ifelse(dat$scroll == '1Qisaa' & dat$chapter > 33, '1QisaaII',
dat$scroll))
dat$scr_book2 <- paste(dat$scroll, dat$book2, sep='_')
mt_sp_books <- unique(dat$scr_book2)
mt_sp_books
dat$scr_book2 <- factor(dat$scr_book2, levels = mt_sp_books)
dat$scroll <- as.factor(dat$scroll)
str(dat)
dat$type
dat$type <- factor(dat$type, levels = c('last', 'first', 'single'))
levels(dat$type)
# Merge single and last syllables in new variable type2
dat$type2 <- ifelse(dat$type %in% c('single', 'last'), 'last', 'first')
dat$type2 <- factor(dat$type2, levels = c('last', 'first'))
dat$lex_type <- paste(dat$lex, dat$type2, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
dat$qsp <- as.factor(dat$qsp)
head(dat)
dat$law_phase2 <- ifelse(dat$book %in% LAW_BOOKS, 'Pent',
ifelse(dat$book %in% EBH_BOOKS, 'FP',
ifelse(dat$book %in% LBH_BOOKS, 'LBH',
'Other')))
dat$law_phase2 <- ifelse(!dat$scroll %in% c(c('MT', 'SP'), QSP_SCROLLS), paste0(dat$law_phase2, '_non_QSP'),
ifelse(dat$scroll %in% QSP_SCROLLS, paste0(dat$law_phase2, '_QSP'),
ifelse(dat$scroll == 'SP', paste0(dat$law_phase2, '_SP'),
dat$law_phase2)))
dat$law_phase2 <- as.factor(dat$law_phase2)
unique(dat$law_phase2)
table(dat$law_phase2)
law_phase2_levels <- c('Pent', 'Pent_SP', 'FP', 'LBH', 'Other',
'Pent_non_QSP', 'FP_non_QSP', 'LBH_non_QSP',
'Other_non_QSP',
'Pent_QSP', 'FP_QSP', 'Other_QSP')
dat$law_phase2 <- factor(dat$law_phase2, levels=law_phase2_levels)
str(dat)
levels(dat$scr_book2)
str(dat)
dim(dat)
dat$pattern == ''
sum(dat$pattern == '')
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
library(ggmcmc)
library(coda)
library(bayestestR) # p_direction
MODEL_FOLDER <- 'C:/Users/geitb/Kopenhagen/KopenhagenResearch/monograph/chapters/NounsAdjectives/models_rstanarm'
IMAGE_FOLDER <- 'C:/Users/geitb/Dropbox/monograph_orthography/nouns_adjectives/images_nouns_adjv'
EBH_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy", "Joshua",
"Judges", "1_Samuel", "2_Samuel", "1_Kings", "2_Kings")
LBH_BOOKS <- c("Esther", "Daniel", "Ezra", "Nehemiah", "1_Chronicles", "2_Chronicles")
LAW_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy")
QSP_SCROLLS <- c('1Qisaa', '1QisaaI', '1QisaaII','2Q3', '4Q13', '4Q20', '2Q7', '4Q27', '1Q4', '2Q12', '4Q37', '4Q38', '4Q38a', '4Q40', '4Q53',
'4Q57', '2Q13', '4Q78', '4Q80', '4Q82', '4Q128', '4Q129', '4Q134', '4Q135', '4Q136',
'4Q137', '4Q138', '4Q139', '4Q140', '4Q141', '4Q142', '4Q143', '4Q144', '4Q158', '4Q364',
'4Q365', '4Q96', '4Q111', '4Q109', '11Q5', '11Q6', '11Q7', '11Q8')
length(QSP_SCROLLS)
logit2prob <- function(logit){
odds <- exp(logit)
prob <- odds / (1 + odds)
return(prob)
}
logit2odds <- function(logit){
odds <- exp(logit)
return(odds)
}
text_sizes = theme(
plot.title = element_text(size = 20),
axis.title.x = element_text(size = 16),
axis.text.x = element_text(size = 14),
axis.title.y = element_blank(),
axis.text.y = element_text(size = 20))
dat <- read.csv('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/data/nouns_adjectives.csv', sep='\t')
dim(dat)
str(dat)
sum(dat$pattern == '')
sum(nchar(dat$pattern == 0))
sum(nchar(dat$pattern) == 0)
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
MODEL_FOLDER <- 'C:/Users/geitb/Kopenhagen/KopenhagenResearch/monograph/chapters/NounsAdjectives/models_rstanarm'
EBH_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy", "Joshua",
"Judges", "1_Samuel", "2_Samuel", "1_Kings", "2_Kings")
LBH_BOOKS <- c("Esther", "Daniel", "Ezra", "Nehemiah", "1_Chronicles", "2_Chronicles")
LAW_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy")
QSP_SCROLLS = c('1Qisaa', '1QisaaI', '1QisaaII', '2Q3', '4Q13', '4Q20', '2Q7', '4Q27', '1Q4', '2Q12', '4Q37', '4Q38', '4Q38a', '4Q40', '4Q53',
'4Q57', '2Q13', '4Q78', '4Q80', '4Q82', '4Q128', '4Q129', '4Q134', '4Q135', '4Q136',
'4Q137', '4Q138', '4Q139', '4Q140', '4Q141', '4Q142', '4Q143', '4Q144', '4Q158', '4Q364',
'4Q365', '4Q96', '4Q111', '4Q109', '11Q5', '11Q6', '11Q7', '11Q8')
length(QSP_SCROLLS)
logit2prob <- function(logit){
odds <- exp(logit)
prob <- odds / (1 + odds)
return(prob)
}
dat <- read.csv('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/data/infc_qal_triliteral.csv', sep='\t')
dim(dat)
head(dat)
str(dat)
unique(dat$book)
sum(is.na(dat$pattern))
sum(table(dat$pattern))
nchar(dat$pattern)
nchar(dat$pattern) == 0
nchar(dat$pattern) == 0 & dat$croll == 'MT'
sum(nchar(dat$pattern) == 0 & dat$croll == 'MT')
!(nchar(dat$pattern) == 0 & dat$croll == 'MT')
(nchar(dat$pattern) == 0 & dat$croll == 'MT')
dat[nchar(dat$pattern) == 0 & dat$croll == 'MT',]
dat[(nchar(dat$pattern) == 0) & dat$croll == 'MT',]
(nchar(dat$pattern) == 0) & dat$croll == 'MT'
nchar(dat$pattern) == 0 & dat$croll == 'MT'
nchar(dat$pattern) == 0
nchar(dat$pattern) == 0 && dat$scroll == 'MT'
nchar(dat$pattern) == 0 & dat$scroll == 'MT'
dat[nchar(dat$pattern) == 0 & dat$scroll == 'MT',]
dat[!nchar(dat$pattern) == 0 & dat$scroll == 'MT',]
dat[!(nchar(dat$pattern) == 0 & dat$scroll == 'MT'),]
dat <- read.csv('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/data/infc_qal_triliteral.csv', sep='\t')
dim(dat)
head(dat)
str(dat)
unique(dat$book)
sum(is.na(dat$pattern))
sum(table(dat$pattern))
dat[(nchar(dat$pattern) == 0) & dat$croll == 'MT',]
dat[!(nchar(dat$pattern) == 0 & dat$scroll == 'MT'),]
# remove ketive/qere
dat <- dat[!(nchar(dat$pattern) == 0 & dat$scroll == 'MT'),]
dat$has_suffix <- as.factor(as.numeric(dat$has_prs | dat$has_nme | dat$has_hloc))
# has_prefix, has_prs, has_nme, lex, book, has_vowel_letter
dat$has_prefix <- as.factor(dat$has_prefix)
dat$has_prs <- as.factor(dat$has_prs)
dat$has_nme <- as.factor(dat$has_nme)
dat$has_hloc <- as.factor(dat$has_hloc)
dat$lex <- as.factor(dat$lex)
dat$book <- as.factor(dat$book)
dat$has_vowel_letter <- as.factor(dat$has_vowel_letter)
dat$type <- as.factor(dat$type)
dat$book2 <- dat$book %>% str_replace('1_', '') |> str_replace('2_', '')
table(dat$book2)
# Make 2 scrolls of 1Qisaa
dat$scroll <- ifelse(dat$scroll == '1Qisaa' & dat$chapter < 34, '1QisaaI',
ifelse(dat$scroll == '1Qisaa' & dat$chapter > 33, '1QisaaII',
dat$scroll))
dat$scroll <- as.factor(dat$scroll)
dat$scr_book2 <- paste(dat$scroll, dat$book2, sep='_')
mt_sp_books <- unique(dat$scr_book2)
mt_sp_books
dat$scr_book2 <- factor(dat$scr_book2, levels = mt_sp_books)
unique(dat$scr_book2)
dat$book2 <- as.factor(dat$book2)
dat$phase <- ifelse(dat$book %in% EBH_BOOKS, 'EBH', ifelse(dat$book %in% LBH_BOOKS, 'LBH', 'NO'))
dat$law_phase <- ifelse(dat$book %in% LAW_BOOKS, 0, ifelse(dat$book %in% EBH_BOOKS, 1,
ifelse(dat$book %in% LBH_BOOKS, 2, 3)))
dat$law_phase <- as.factor(dat$law_phase)
dat$qsp_sp <- ifelse(dat$scroll %in% QSP_SCROLLS, 'QSP', ifelse(dat$scroll == 'SP', 'SP', 'Other'))
dat$qsp_sp <- as.factor(dat$qsp_sp)
table(dat$qsp_sp)
str(dat)
dat$type
dat$type <- factor(dat$type, levels = c('last', 'first', 'single'))
levels(dat$type)
# Merge single and last syllables in new variable type2
dat$type2 <- ifelse(dat$type %in% c('single', 'last'), 'last', 'first')
dat$type2 <- factor(dat$type2, levels = c('last', 'first'))
dat$lex_type <- paste(dat$lex, dat$type2, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
dat$law_phase2 <- ifelse(dat$book %in% LAW_BOOKS, 'Pent',
ifelse(dat$book %in% EBH_BOOKS, 'FP',
ifelse(dat$book %in% LBH_BOOKS, 'LBH',
'Other')))
dat$law_phase2 <- ifelse(!dat$scroll %in% c(c('MT', 'SP'), QSP_SCROLLS), paste0(dat$law_phase2, '_non_QSP'),
ifelse(dat$scroll %in% QSP_SCROLLS, paste0(dat$law_phase2, '_QSP'),
ifelse(dat$scroll == 'SP', paste0(dat$law_phase2, '_SP'),
dat$law_phase2)))
dat$law_phase2 <- as.factor(dat$law_phase2)
law_phase2_levels <- c('Pent', 'Pent_SP', 'FP', 'LBH', 'Other',
'Pent_non_QSP', 'FP_non_QSP', 'LBH_non_QSP',
'Other_non_QSP',
'Pent_QSP', 'FP_QSP', 'Other_QSP')
dat$law_phase2 <- factor(dat$law_phase2, levels=law_phase2_levels)
dat[is.na(dat$law_phase2),]
dim(dat)
head(dat)
table(dat$scroll)
table(dat$qsp_sp)
3141-2491-335
mt_sp <- dat |> filter(scroll %in% c('SP', 'MT'))
str(mt_sp)
mt_sp <- droplevels(mt_sp)
table(mt_sp$type2)
variation_lex_type_list <- list()
# Last radical
substr(dat$lex, 3, 3)
# Last radical
mt <- dat |> filter(scroll == 'MT')
substr(mt$lex, 3, 3)
mt$last_radical <- substr(mt$lex, 3, 3)
# Last radical
mt <- dat |> filter(scroll == 'MT')
mt$last_radical <- substr(mt$lex, 3, 3)
table(mt$last_radical, mt$has_vowel_letter)
prop.table(table(mt$last_radical, mt$has_vowel_letter), margin=1)
# second radical
mt <- dat |> filter(scroll == 'MT')
mt$sec_radical <- substr(mt$lex, 2, 2)
table(mt$sec_radical, mt$has_vowel_letter)
# first radical
mt <- dat |> filter(scroll == 'MT')
mt$first_radical <- substr(mt$lex, 1, 1)
table(mt$first_radical, mt$has_vowel_letter)
prop.table(table(mt$first_radical, mt$has_vowel_letter), margin=1)
fit_brm_model <- function(data, formula, warmup, iter, adapt_delta) {
trace <- brm(formula = formula,
prior = set_prior("normal(0, 5)", class = "Intercept") +
set_prior("normal(0, 5)", class = "b"),
data = data,
family = bernoulli(link = "logit"),
warmup = warmup,
iter = iter,
chains = 4,
cores=4,
control = list(adapt_delta = adapt_delta),
seed = 123)
return(trace)
}
formula_mt_infc <- has_vowel_letter ~
has_suffix*qsp_sp +
has_prefix*qsp_sp +
(has_suffix + has_prefix | scr_book2) +
(has_suffix + has_prefix | lex_type)
table(dat$scroll)
fit_brm_model <- function(data, formula, warmup, iter, adapt_delta) {
trace <- brm(formula = formula,
prior = set_prior("normal(0, 5)", class = "Intercept") +
set_prior("normal(0, 5)", class = "b"),
data = data,
family = bernoulli(link = "logit"),
warmup = warmup,
iter = iter,
chains = 4,
cores=4,
control = list(adapt_delta = adapt_delta),
seed = 123)
return(trace)
}
formula_mt_infc <- has_vowel_letter ~
has_suffix*qsp_sp +
has_prefix*qsp_sp +
(has_suffix + has_prefix | scr_book2) +
(has_suffix + has_prefix | lex_type)
bayes_model_mt_sp_dss_ptca <- fit_brm_model(dat,
formula_mt_dss_infc,
2000, 4000, 0.95)
formula_infc <- has_vowel_letter ~
has_suffix*qsp_sp +
has_prefix*qsp_sp +
(has_suffix + has_prefix | scr_book2) +
(has_suffix + has_prefix | lex_type)
bayes_model_mt_sp_dss_ptca <- fit_brm_model(dat,
formula_infc,
2000, 4000, 0.95)
summary(bayes_model_mt_dss_infc)
formula_infc <- has_vowel_letter ~
has_suffix*qsp_sp +
has_prefix*qsp_sp +
(has_suffix + has_prefix | scr_book2) +
(has_suffix + has_prefix | lex_type)
bayes_model_infc <- fit_brm_model(dat,
formula_infc,
2000, 4000, 0.95)
summary(bayes_mode_infc)
summary(bayes_model_infc)
table(dat$law_phase2)
dat <- droplevels(dat)
table(dat$law_phase2)
dat <- droplevels(dat)
formula_infc <- has_vowel_letter ~
has_suffix*law_phase2 +
has_prefix*law_phase2 +
(has_suffix + has_prefix | scr_book2) +
(has_suffix + has_prefix | lex_type)
bayes_model_infc <- fit_brm_model(dat,
formula_infc,
2000, 4000, 0.95)
bayes_model_infc <- fit_brm_model(dat,
formula_infc,
2000, 4000, 0.97)
bayes_model_infc <- fit_brm_model(dat,
formula_infc,
3000, 6000, 0.97)
bayes_model_infc <- fit_brm_model(dat,
formula_infc,
3000, 6000, 0.99)
summary(bayes_model_infc)
ranef(bayes_model_infc)
bayes_R2(bayes_model_infc)
p_direction(bayes_model_infc)
file_path_mt_dss_infc <- file.path(MODEL_FOLDER, 'bayes_model_mt_dss_affix_effect_infc.rds')
saveRDS(bayes_model_infc, file = file_path_mt_dss_infc)
p_direction(bayes_model_infc)
library(bayestestR)
p_direction(bayes_model_infc)
p_dir <- p_direction(bayes_model_infc)
str(p_dir)
p_dir$pd
summary(bayes_model_infc)
fixef(bayes_model_infc)
fixed_effects <- fixef(bayes_model_infc)
fixed_effects$pd <- p_dir$pd
fixed_effects
fixed_effects <- fixef(bayes_model_infc)
str(fixed_effects)
fixed_effects
str(fixed_effects)
as.data.frame(fixed_effects)
fixed_effects$pd <- p_dir$pd
fixed_effects
fixed_effects <- fixef(bayes_model_infc)
str(fixed_effects)
fixed_effects <- as.data.frame(fixed_effects)
fixed_effects$pd <- p_dir$pd
fixed_effects
trace_mt <- readRDS(file_path_mt_dss_infc)
model_vars <- get_variables(trace_mt)
model_vars
fixed_draws <- trace_mt %>%
spread_draws(               b_Intercept,  b_has_suffix1,
b_law_phase2FP, b_law_phase2LBH,
b_law_phase2Other,  b_law_phase2Pent_non_QSP,
b_law_phase2FP_non_QSP, b_law_phase2LBH_non_QSP,
b_law_phase2Other_non_QSP,  b_law_phase2Pent_QSP,
b_law_phase2FP_QSP, b_law_phase2Other_QSP,
b_has_prefix1,  `b_has_suffix1:law_phase2FP`,
`b_has_suffix1:law_phase2LBH`,  `b_has_suffix1:law_phase2Other`,
`b_has_suffix1:law_phase2Pent_non_QSP`, `b_has_suffix1:law_phase2FP_non_QSP`,
`b_has_suffix1:law_phase2LBH_non_QSP`,  `b_has_suffix1:law_phase2Other_non_QSP`,
`b_has_suffix1:law_phase2Pent_QSP`, `b_has_suffix1:law_phase2FP_QSP`,
`b_has_suffix1:law_phase2Other_QSP`,  `b_law_phase2FP:has_prefix1`,
`b_law_phase2LBH:has_prefix1`,  `b_law_phase2Other:has_prefix1`,
`b_law_phase2Pent_non_QSP:has_prefix1`, `b_law_phase2FP_non_QSP:has_prefix1`,
`b_law_phase2LBH_non_QSP:has_prefix1`,  `b_law_phase2Other_non_QSP:has_prefix1`,
`b_law_phase2Pent_QSP:has_prefix1`, `b_law_phase2FP_QSP:has_prefix1`,
`b_law_phase2Other_QSP:has_prefix1`
)
head(fixed_draws)
summary_first_prefix_mt <- fixed_draws %>%
transmute('Intercept MT Pentateuch' = b_Intercept,
'With Prefix MT Pentateuch' = b_Intercept + b_has_prefix1,
'Intercept MT Former Prophets' = b_Intercept + b_law_phase2FP,
'With Prefix MT Former Prophets' = b_Intercept + b_has_prefix1 + b_law_phase2FP + `b_law_phase2FP:has_prefix1`,
'Intercept MT LBH' = b_Intercept + b_law_phase2LBH,
'With Prefix MT LBH' = b_Intercept + b_has_prefix1 + b_law_phase2LBH + `b_law_phase2LBH:has_prefix1`,
'Intercept MT Other' = b_Intercept + b_law_phase2Other,
'With Prefix MT Other' = b_Intercept + b_has_prefix1 + b_law_phase2Other + `b_law_phase2Other:has_prefix1`,
) %>%
gather() %>%
group_by(key) %>%
mean_hdi(.width = c(.95, .66))
labels_prefix <- c(
'With Prefix MT Other',
'Intercept MT Other',
'With Prefix MT LBH',
'Intercept MT LBH',
'With Prefix MT Former Prophets',
'Intercept MT Former Prophets',
'With Prefix MT Pentateuch',
'Intercept MT Pentateuch'
)
summary_first_prefix_mt$key <- factor(summary_first_prefix_mt$key, levels = labels_prefix)
summary_first_prefix_mt %>%
ggplot(aes(y = key, x = value, xmin = .lower, xmax = .upper)) +
geom_pointinterval() +
ggtitle('Logodds of a vowel letter in an active participle with or without a prefix in Other, SP and QSP')
summary_first_prefix_mt
summary_first_prefix_mt$value_prob <- logit2prob(summary_first_prefix_mt)
summary_first_prefix_mt$value_prob <- logit2prob(summary_first_prefix_mt$value)
summary_first_prefix_mt$value_prob <- logit2prob(summary_first_prefix_mt$value)
summary_first_prefix_mt$.lower_prob <- logit2prob(summary_first_prefix_mt$.lower)
summary_first_prefix_mt$.upper_prob <- logit2prob(summary_first_prefix_mt$.upper)
# probability
summary_first_prefix_mt %>%
ggplot(aes(y = key, x = value_prob, xmin = .lower_prob, xmax = .upper_prob)) +
geom_pointinterval() +
ggtitle('Logodds of a vowel letter in an active participle with or without a prefix in MT')
table(dat$law_phase2)
