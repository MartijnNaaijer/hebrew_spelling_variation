ggplot(data = hpd_ay_ay, aes(x = lex , y = mean)) +
geom_bar(stat = "identity", color = "black", position = position_dodge()) +
labs(x = '', y = 'Fraction of full spelling') +
geom_errorbar( aes(x=lex, ymin=lower, ymax=upper), width=0.4, colour='black', alpha=0.9,
linewidth=1.3,
position = position_dodge(0.9)) +
theme_minimal() +
theme(text = element_text(size = 20)) +
theme(axis.text.x = element_text(angle = 90, hjust=-1)) +
scale_fill_discrete(name = '', labels = c('Without suffix', 'With suffix'))
ggplot(data = hpd_ay_ay, aes(x = lex , y = mean)) +
geom_bar(stat = "identity", color = "black", position = position_dodge()) +
labs(x = '', y = 'Fraction of full spelling') +
geom_errorbar( aes(x=lex, ymin=lower, ymax=upper), width=0.4, colour='black', alpha=0.9,
linewidth=1.3,
position = position_dodge(0.9)) +
theme_minimal() +
theme(text = element_text(size = 20)) +
theme(axis.text.x = element_text(angle = 90, hjust=0)) +
scale_fill_discrete(name = '', labels = c('Without suffix', 'With suffix'))
ggplot(data = hpd_ay_ay, aes(x = lex , y = mean)) +
geom_bar(stat = "identity", color = "black", position = position_dodge()) +
labs(x = '', y = 'Fraction of full spelling') +
geom_errorbar( aes(x=lex, ymin=lower, ymax=upper), width=0.4, colour='black', alpha=0.9,
linewidth=1.3,
position = position_dodge(0.9)) +
theme_minimal() +
theme(text = element_text(size = 20)) +
theme(axis.text.x = element_text(angle = 90, hjust=0, vjust=1)) +
scale_fill_discrete(name = '', labels = c('Without suffix', 'With suffix'))
ggplot(data = hpd_ay_ay, aes(x = lex , y = mean)) +
geom_bar(stat = "identity", color = "black", position = position_dodge()) +
labs(x = '', y = 'Fraction of full spelling') +
geom_errorbar( aes(x=lex, ymin=lower, ymax=upper), width=0.4, colour='black', alpha=0.9,
linewidth=1.3,
position = position_dodge(0.9)) +
theme_minimal() +
theme(text = element_text(size = 20)) +
theme(axis.text.x = element_text(angle = 90, hjust=0, vjust=5)) +
scale_fill_discrete(name = '', labels = c('Without suffix', 'With suffix'))
ggplot(data = hpd_ay_ay, aes(x = lex , y = mean)) +
geom_bar(stat = "identity", color = "black", position = position_dodge()) +
labs(x = '', y = 'Fraction of full spelling') +
geom_errorbar( aes(x=lex, ymin=lower, ymax=upper), width=0.4, colour='black', alpha=0.9,
linewidth=1.3,
position = position_dodge(0.9)) +
theme_minimal() +
theme(text = element_text(size = 20)) +
theme(axis.text.x = element_text(angle = 90, hjust=0, vjust=-1)) +
scale_fill_discrete(name = '', labels = c('Without suffix', 'With suffix'))
ggplot(data = hpd_ay_ay, aes(x = lex , y = mean)) +
geom_bar(stat = "identity", color = "black", position = position_dodge()) +
labs(x = '', y = 'Fraction of full spelling') +
geom_errorbar( aes(x=lex, ymin=lower, ymax=upper), width=0.4, colour='black', alpha=0.9,
linewidth=1.3,
position = position_dodge(0.9)) +
theme_minimal() +
theme(text = element_text(size = 20)) +
theme(axis.text.x = element_text(angle = 90, hjust=0, vjust=-0.5)) +
scale_fill_discrete(name = '', labels = c('Without suffix', 'With suffix'))
ggplot(data = hpd_ay_ay, aes(x = lex , y = mean)) +
geom_bar(stat = "identity", color = "black", position = position_dodge()) +
labs(x = '', y = 'Fraction of full spelling') +
geom_errorbar( aes(x=lex, ymin=lower, ymax=upper), width=0.4, colour='black', alpha=0.9,
linewidth=1.3,
position = position_dodge(0.9)) +
theme_minimal() +
theme(text = element_text(size = 20)) +
theme(axis.text.x = element_text(angle = 90, hjust=0, vjust=-0.2)) +
scale_fill_discrete(name = '', labels = c('Without suffix', 'With suffix'))
ggplot(data = hpd_ay_ay, aes(x = lex , y = mean)) +
geom_bar(stat = "identity", color = "black", position = position_dodge()) +
labs(x = '', y = 'Fraction of full spelling') +
geom_errorbar( aes(x=lex, ymin=lower, ymax=upper), width=0.4, colour='black', alpha=0.9,
linewidth=1.3,
position = position_dodge(0.9)) +
theme_minimal() +
theme(text = element_text(size = 20)) +
theme(axis.text.x = element_text(angle = 90, hjust=0, vjust=-0.1)) +
scale_fill_discrete(name = '', labels = c('Without suffix', 'With suffix'))
ggplot(data = hpd_ay_ay, aes(x = lex , y = mean)) +
geom_bar(stat = "identity", color = "black", position = position_dodge()) +
labs(x = '', y = 'Fraction of full spelling') +
geom_errorbar( aes(x=lex, ymin=lower, ymax=upper), width=0.4, colour='black', alpha=0.9,
linewidth=1.3,
position = position_dodge(0.9)) +
theme_minimal() +
theme(text = element_text(size = 20)) +
theme(axis.text.x = element_text(angle = 90, hjust=0, vjust=-0)) +
scale_fill_discrete(name = '', labels = c('Without suffix', 'With suffix'))
ggplot(data = hpd_ay_ay, aes(x = lex , y = mean)) +
geom_bar(stat = "identity", color = "black", position = position_dodge()) +
labs(x = '', y = 'Fraction of full spelling') +
geom_errorbar( aes(x=lex, ymin=lower, ymax=upper), width=0.4, colour='black', alpha=0.9,
linewidth=1.3,
position = position_dodge(0.9)) +
theme_minimal() +
theme(text = element_text(size = 20)) +
theme(axis.text.x = element_text(angle = 90, hjust=0, vjust=0.1)) +
scale_fill_discrete(name = '', labels = c('Without suffix', 'With suffix'))
ggplot(data = hpd_ay_ay, aes(x = lex , y = mean)) +
geom_bar(stat = "identity", color = "black", position = position_dodge()) +
labs(x = '', y = 'Fraction of full spelling') +
geom_errorbar( aes(x=lex, ymin=lower, ymax=upper), width=0.4, colour='black', alpha=0.9,
linewidth=1.3,
position = position_dodge(0.9)) +
theme_minimal() +
theme(text = element_text(size = 20)) +
theme(axis.text.x = element_text(angle = 90, hjust=0, vjust=0.2)) +
scale_fill_discrete(name = '', labels = c('Without suffix', 'With suffix'))
ggsave(file.path(IMAGE_FOLDER, 'explore_lexemes.png'))
table(hlk$scroll)
hlk <- dat |> filter(lex == 'HLK[')
hlk_mt <- hlk |> filter(scroll == 'MT')
hlk_mt <- hlk |> filter(scroll == 'MT')
table(hlk_mt$book2, hlk_mt$has_vowel_letter)
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
library(bayestestR)
library(binom)
IMAGE_FOLDER <- 'C:/Users/geitb/Dropbox/monograph_orthography/verbs/images_pe_yod_hiph'
scripts_path <- 'C:/Users/geitb/Dropbox/monograph_orthography/verbs'
functions_path <- file.path(scripts_path, 'functions.R')
config_path <- file.path(scripts_path, 'config.R')
source(functions_path)
source(config_path)
YOD_VERBS <- c('JBC[', 'JNQ[', 'JCR[', 'JVB[', 'JQY[', 'JLL[', 'JMN[')
II_TSADE_VERBS <- c('JY<[', 'JYG[', 'JYQ[', 'JYR[', 'JYT[')
DATASET <- 'niph_hiph_pe_yod.csv'
dat <- import_bib_data(DATA_FOLDER, DATASET)
dat <- dat |>
remove_ketiv_qere() |>
add_col_has_suffix() |>
make_book2_column() |>
make_scr_book2_column() |>
make_law_phase_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS) |>
make_law_phase2_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS, QSP_SCROLLS, law_phase2_levels) |>
make_law_phase3_column(QSP_SCROLLS) |>
split_isaiah_scroll() |>
make_factor_columns(factor_columns) |>
droplevels()
dat$qsp_sp <- ifelse(dat$scroll %in% QSP_SCROLLS, 'QSP', ifelse(dat$scroll == 'MT', 'MT', 'Other'))
dat$qsp_sp <- as.factor(dat$qsp_sp)
# Revalue all participles to "participle"
dat$vt <- ifelse(dat$vt %in% c('ptcp', 'ptca'), 'participle', dat$vt)
dat$yod_verb <- ifelse(dat$lex %in% YOD_VERBS, 1, 0)
# Remove II-Tsade verbs
dat_ii_tsade <- dat |> filter(lex %in% II_TSADE_VERBS) |> droplevels()
dat <- dat |> filter(!(lex %in% II_TSADE_VERBS)) |> droplevels()
dat$vs <- as.factor(dat$vs)
levels(dat$vs)
dat$first_char <- substr(dat$g_cons, 1, 1)
table(dat$vt)
dim(dat)
table(dat$qsp_sp)
table(dat$lex)
table(dat$law_phase3)
table(dat$first_char, dat$has_vowel_letter)
jya <- dat |> filter(lex == 'JY>[') |> droplevels()
head(jya, 25)
all_ii_tsade <- rbind(dat_ii_tsade, jya)
table(all_ii_tsade$vs, all_ii_tsade$has_vowel_letter)
table(all_ii_tsade$vs, all_ii_tsade$has_vowel_letter, all_ii_tsade$lex)
all_ii_tsade |> filter(lex == 'JYR[')
head(dat)
table(dat$vs, dat$yod_verb)
dat_w <- dat |> filter(yod_verb == 0)
dat_y <- dat |> filter(yod_verb == 1)
table(dat_y$vs, dat_y$vt)
table(dat_w$vt, dat_w$has_vowel_letter, dat_w$vs)
hlk <- dat |> filter(lex == 'HLK[')
dim(hlk)
table(hlk$vt, hlk$has_vowel_letter)
table(hlk$vs)
head(hlk)
tail(hlk)
table(hlk$scroll)
table(hlk$vowel_letter)
table(dat$vowel_letter)
head(dat |> filter(vowel_letter == 'J'))
hlk_mt <- hlk |> filter(scroll == 'MT')
table(hlk_mt$book2, hlk_mt$has_vowel_letter)
hlk_mt |> filter(book2 == 'Kings')
'J' %in% dat$stem
grep('J', dat$stem)
str_detect('J', dat$stem)
str_detect('J', c('J', 'JA', 'AAP'))
str_detect(dat$stem, 'J')
has_yod <- str_detect(dat$stem, 'J')
dat$has_hif_yod <- str_detect(dat$stem, 'J')
dat_hif <- dat |> filter(vs == 'hif')
table(dat_hif$has_hif_yod, dat_hif$has_vowel_letter)
table(dat$has_hif_yod, dat$has_vowel_letter)
mosaicplot(table(dat$has_hif_yod, dat$has_vowel_letter))
head(dat)
table(dat$first_char, dat$has_vowel_letter)
table(dat_hif$first_char, dat_hif$has_vowel_letter)
mosaicplot(table(dat_hif$first_char, dat_hif$has_vowel_letter))
mosaicplot(table(dat$first_char, dat$has_vowel_letter))
mosaicplot(table(dat$has_hif_yod, dat$has_vowel_letter))
mosaicplot(table(dat_hif$first_char, dat_hif$has_vowel_letter))
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
library(bayestestR)
library(binom)
IMAGE_FOLDER <- 'C:/Users/geitb/Dropbox/monograph_orthography/verbs/images_pe_yod_hiph'
scripts_path <- 'C:/Users/geitb/Dropbox/monograph_orthography/verbs'
functions_path <- file.path(scripts_path, 'functions.R')
config_path <- file.path(scripts_path, 'config.R')
source(functions_path)
source(config_path)
YOD_VERBS <- c('JBC[', 'JNQ[', 'JCR[', 'JVB[', 'JQY[', 'JLL[', 'JMN[')
II_TSADE_VERBS <- c('JY<[', 'JYG[', 'JYQ[', 'JYR[', 'JYT[')
DATASET <- 'niph_hiph_pe_yod.csv'
dat <- import_bib_data(DATA_FOLDER, DATASET)
dat <- dat |>
remove_ketiv_qere() |>
add_col_has_suffix() |>
make_book2_column() |>
make_scr_book2_column() |>
make_law_phase_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS) |>
make_law_phase2_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS, QSP_SCROLLS, law_phase2_levels) |>
make_law_phase3_column(QSP_SCROLLS) |>
split_isaiah_scroll() |>
make_factor_columns(factor_columns) |>
droplevels()
dat$qsp_sp <- ifelse(dat$scroll %in% QSP_SCROLLS, 'QSP', ifelse(dat$scroll == 'MT', 'MT', 'Other'))
dat$qsp_sp <- as.factor(dat$qsp_sp)
# Revalue all participles to "participle"
dat$vt <- ifelse(dat$vt %in% c('ptcp', 'ptca'), 'participle', dat$vt)
dat$yod_verb <- ifelse(dat$lex %in% YOD_VERBS, 1, 0)
# Remove II-Tsade verbs
dat_ii_tsade <- dat |> filter(lex %in% II_TSADE_VERBS) |> droplevels()
dat <- dat |> filter(!(lex %in% II_TSADE_VERBS)) |> droplevels()
dat$vs <- as.factor(dat$vs)
levels(dat$vs)
dat$first_char <- substr(dat$g_cons, 1, 1)
dat$has_hif_yod <- str_detect(dat$stem, 'J')
table(dat$vt)
dim(dat)
table(dat$qsp_sp)
table(dat$lex)
table(dat$law_phase3)
table(dat$first_char, dat$has_vowel_letter)
jya <- dat |> filter(lex == 'JY>[') |> droplevels()
head(jya, 25)
all_ii_tsade <- rbind(dat_ii_tsade, jya)
table(all_ii_tsade$vs, all_ii_tsade$has_vowel_letter)
table(all_ii_tsade$vs, all_ii_tsade$has_vowel_letter, all_ii_tsade$lex)
all_ii_tsade |> filter(lex == 'JYR[')
head(dat)
table(dat$has_hif_yod, dat$has_vowel_letter)
mosaicplot(table(dat$has_hif_yod, dat$has_vowel_letter))
mosaicplot(table(dat_hif$first_char, dat_hif$has_vowel_letter))
mosaicplot(table(dat$first_char, dat$has_vowel_letter))
dat_hif <- dat |> filter(vs == 'hif')
table(dat_hif$has_hif_yod, dat_hif$has_vowel_letter)
table(dat$has_hif_yod, dat$has_vowel_letter)
table(dat_hif$first_char, dat_hif$has_vowel_letter)
mosaicplot(table(dat_hif$first_char, dat_hif$has_vowel_letter))
dat_hif |> filter(first_char == 'N')
table(dat$has_hif_yod, dat$has_vowel_letter)
table(dat$has_hif_yod, dat$has_vowel_letter)
table(dat_hif$has_hif_yod, dat_hif$has_vowel_letter)
dat_hif_no_jbc_jsp <- dat_hif |> filter(!lex %in% c('JBC[', 'JSP['))
table(dat_hif_no_jbc_jsp$has_hif_yod, dat_hif_no_jbc_jsp$has_vowel_letter)
table(dat_hif_no_jbc_jsp$first_char, dat_hif_no_jbc_jsp$has_vowel_letter)
mosaicplot(table(dat_hif_no_jbc_jsp$has_hif_yod, dat_hif_no_jbc_jsp$has_vowel_letter))
mosaicplot(table(dat_hif_no_jbc_jsp$first_char, dat_hif_no_jbc_jsp$has_vowel_letter))
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
library(bayestestR)
library(binom)
IMAGE_FOLDER <- 'C:/Users/geitb/Dropbox/monograph_orthography/verbs/images_pe_yod_hiph'
scripts_path <- 'C:/Users/geitb/Dropbox/monograph_orthography/verbs'
functions_path <- file.path(scripts_path, 'functions.R')
config_path <- file.path(scripts_path, 'config.R')
source(functions_path)
source(config_path)
YOD_VERBS <- c('JBC[', 'JNQ[', 'JCR[', 'JVB[', 'JQY[', 'JLL[', 'JMN[')
II_TSADE_VERBS <- c('JY<[', 'JYG[', 'JYQ[', 'JYR[', 'JYT[')
DATASET <- 'niph_hiph_pe_yod.csv'
dat <- import_bib_data(DATA_FOLDER, DATASET)
dat <- dat |>
remove_ketiv_qere() |>
add_col_has_suffix() |>
make_book2_column() |>
make_scr_book2_column() |>
make_law_phase_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS) |>
make_law_phase2_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS, QSP_SCROLLS, law_phase2_levels) |>
make_law_phase3_column(QSP_SCROLLS) |>
split_isaiah_scroll() |>
make_factor_columns(factor_columns) |>
droplevels()
dat$qsp_sp <- ifelse(dat$scroll %in% QSP_SCROLLS, 'QSP', ifelse(dat$scroll == 'MT', 'MT', 'Other'))
dat$qsp_sp <- as.factor(dat$qsp_sp)
# Revalue all participles to "participle"
dat$vt <- ifelse(dat$vt %in% c('ptcp', 'ptca'), 'participle', dat$vt)
dat$yod_verb <- ifelse(dat$lex %in% YOD_VERBS, 1, 0)
# Remove II-Tsade verbs
dat_ii_tsade <- dat |> filter(lex %in% II_TSADE_VERBS) |> droplevels()
dat <- dat |> filter(!(lex %in% II_TSADE_VERBS)) |> droplevels()
dat$vs <- as.factor(dat$vs)
levels(dat$vs)
dat$first_char <- substr(dat$g_cons, 1, 1)
dat$has_hif_yod <- str_detect(dat$stem, 'J')
table(dat$vt)
dim(dat)
table(dat$qsp_sp)
table(dat$lex)
table(dat$law_phase3)
dat_no_jsp_jbc <- dat |> filter(!lex %in% c('JBC[', 'JSP[')) |> droplevels()
dim(dat)
dim(dat_no_jsp_jbc)
head(dat)
str(dat)
table(dat$law_phase2)
prior_intercept_prob_no_jsp_jbc <- mean(as.numeric(as.character(dat_no_jsp_jbc$has_vowel_letter)))
prior_intercept_logit_no_jsp_jbc <- prob2logit(prior_intercept_prob_no_jsp_jbc)
formula_mt_dss_vt <- has_vowel_letter ~
vt +
(1 | scr_book2/lex)
bayes_model_mt_dss_vt <- fit_brm_model(dat_no_jsp_jbc,
formula_mt_dss_vt,
5000, 15000, 0.95,
prior_intercept_logit_no_jsp_jbc)
summary(bayes_model_mt_dss_vt)
file_path_mt_dss_vt <- file.path(MODEL_FOLDER, 'bayes_model_mt_dss_pe_waw_hif_nif_vt.rds')
saveRDS(bayes_model_mt_dss_vt, file = file_path_mt_dss_vt)
# MAKE PUBLISHABLE TABLE OF SUMMARY
library(htmlTable)
library(kableExtra)
library(magick)
model <- bayes_model_mt_dss_vt
fixed <- summary(model)$fixed
fixed$Rhat <- sprintf('%.2f', fixed$Rhat)
round_names <- c('Estimate', 'Est.Error', 'l-95% CI', 'u-95% CI')
for (name in round_names) {
fixed[,name] <- fixed[,name] |> round(2)
}
fixed$Bulk_ESS <- round(fixed$Bulk_ESS, 0)
fixed$Tail_ESS <- round(fixed$Tail_ESS, 0)
p_dir <- model |> p_direction()
fixed$pd <- round(p_dir$pd,2)
fixed |> htmlTable() |>
save_kable(file = file.path(IMAGE_FOLDER, 'summary_ni_hi_pe_yod_table_model_vt.png'))
install.packages('webshot2')
fixed |> htmlTable() |>
save_kable(file = file.path(IMAGE_FOLDER, 'summary_ni_hi_pe_yod_table_model_vt.png'))
fixed |> htmlTable() |>
save_kable(file = file.path(IMAGE_FOLDER, 'summary_ni_hi_pe_yod_table_model_vt.png'))
fixed |> htmlTable()
fixed_draws <- bayes_model_mt_dss_vt %>%
spread_draws(b_Intercept, b_vtimpv,
b_vtinfa,  b_vtinfc,
b_vtperf,  b_vtparticiple,
b_vtwayq
)
summary_mt_dss <- fixed_draws %>%
transmute('Imperfect (Intercept)' = b_Intercept,
'Imperative' = b_Intercept + b_vtimpv,
'Infinitive absolute' = b_Intercept + b_vtinfa,
'Infinitive construct' = b_Intercept + b_vtinfc,
'Perfect' = b_Intercept + b_vtperf,
'Participle' = b_Intercept + b_vtparticiple,
'Wayyiqtol' = b_Intercept + b_vtwayq,
) %>%
gather() %>%
group_by(key) %>%
mean_hdi(.width = c(.95, .66))
summary_mt_dss
labels <- c(
'Wayyiqtol',
'Perfect',
'Infinitive construct',
'Infinitive absolute',
'Participle',
'Imperative',
'Imperfect (Intercept)'
)
summary_mt_dss$key <- factor(summary_mt_dss$key, levels = labels)
summary_mt_dss %>%
ggplot(aes(y = key, x = value, xmin = .lower, xmax = .upper)) +
geom_pointinterval() +
xlab('Log odds') +
ylab('') +
ggtitle('')
ggsave(file.path(IMAGE_FOLDER, 'model_pe_yod_hif_nif_vt.png'))
prior_intercept_prob <- mean(as.numeric(as.character(dat$has_vowel_letter)))
prior_intercept_logit <- prob2logit(prior_intercept_prob)
bayes_model_mt_dss_vt2 <- fit_brm_model(dat,
formula_mt_dss_vt,
5000, 15000, 0.95,
prior_intercept_logit)
summary(bayes_model_mt_dss_vt2)
file_path_mt_dss_vt2 <- file.path(MODEL_FOLDER, 'bayes_model_mt_dss_pe_waw_hif_nif_vt2.rds')
saveRDS(bayes_model_mt_dss_vt2, file = file_path_mt_dss_vt2)
summary(bayes_model_mt_dss_vt2)
# MAKE PUBLISHABLE TABLE OF SUMMARY
library(htmlTable)
library(kableExtra)
library(magick)
model <- bayes_model_mt_dss_vt2
fixed <- summary(model)$fixed
fixed$Rhat <- sprintf('%.2f', fixed$Rhat)
round_names <- c('Estimate', 'Est.Error', 'l-95% CI', 'u-95% CI')
for (name in round_names) {
fixed[,name] <- fixed[,name] |> round(2)
}
fixed$Bulk_ESS <- round(fixed$Bulk_ESS, 0)
fixed$Tail_ESS <- round(fixed$Tail_ESS, 0)
p_dir <- model |> p_direction()
fixed$pd <- round(p_dir$pd,2)
fixed |> htmlTable()
fixed |> htmlTable()
fixed |> htmlTable() |>
save_kable(file = file.path(IMAGE_FOLDER, 'summary_ni_hi_pe_yod_table_model_vt2.png'))
fixed_draws <- bayes_model_mt_dss_vt2 %>%
spread_draws(b_Intercept, b_vtimpv,
b_vtinfa,  b_vtinfc,
b_vtperf,  b_vtparticiple,
b_vtwayq
)
summary_mt_dss <- fixed_draws %>%
transmute('Imperfect (Intercept)' = b_Intercept,
'Imperative' = b_Intercept + b_vtimpv,
'Infinitive absolute' = b_Intercept + b_vtinfa,
'Infinitive construct' = b_Intercept + b_vtinfc,
'Perfect' = b_Intercept + b_vtperf,
'Participle' = b_Intercept + b_vtparticiple,
'Wayyiqtol' = b_Intercept + b_vtwayq,
) %>%
gather() %>%
group_by(key) %>%
mean_hdi(.width = c(.95, .66))
summary_mt_dss
labels <- c(
'Wayyiqtol',
'Perfect',
'Infinitive construct',
'Infinitive absolute',
'Participle',
'Imperative',
'Imperfect (Intercept)'
)
summary_mt_dss$key <- factor(summary_mt_dss$key, levels = labels)
summary_mt_dss %>%
ggplot(aes(y = key, x = value, xmin = .lower, xmax = .upper)) +
geom_pointinterval() +
xlab('Log odds') +
ylab('') +
ggtitle('')
ggsave(file.path(IMAGE_FOLDER, 'model_pe_yod_hif_nif_vt2.png'))
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
library(bayestestR)
library(binom)
IMAGE_FOLDER <- 'C:/Users/geitb/Dropbox/monograph_orthography/verbs/images_pe_yod_hiph'
scripts_path <- 'C:/Users/geitb/Dropbox/monograph_orthography/verbs'
functions_path <- file.path(scripts_path, 'functions.R')
config_path <- file.path(scripts_path, 'config.R')
source(functions_path)
source(config_path)
YOD_VERBS <- c('JBC[', 'JNQ[', 'JCR[', 'JVB[', 'JQY[', 'JLL[', 'JMN[')
II_TSADE_VERBS <- c('JY<[', 'JYG[', 'JYQ[', 'JYR[', 'JYT[')
DATASET <- 'niph_hiph_pe_yod.csv'
dat <- import_bib_data(DATA_FOLDER, DATASET)
dat <- dat |>
remove_ketiv_qere() |>
add_col_has_suffix() |>
make_book2_column() |>
make_scr_book2_column() |>
make_law_phase_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS) |>
make_law_phase2_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS, QSP_SCROLLS, law_phase2_levels) |>
make_law_phase3_column(QSP_SCROLLS) |>
split_isaiah_scroll() |>
make_factor_columns(factor_columns) |>
droplevels()
dat$qsp_sp <- ifelse(dat$scroll %in% QSP_SCROLLS, 'QSP', ifelse(dat$scroll == 'MT', 'MT', 'Other'))
dat$qsp_sp <- as.factor(dat$qsp_sp)
# Revalue all participles to "participle"
dat$vt <- ifelse(dat$vt %in% c('ptcp', 'ptca'), 'participle', dat$vt)
dat$yod_verb <- ifelse(dat$lex %in% YOD_VERBS, 1, 0)
# Remove II-Tsade verbs
dat_ii_tsade <- dat |> filter(lex %in% II_TSADE_VERBS) |> droplevels()
dat <- dat |> filter(!(lex %in% II_TSADE_VERBS)) |> droplevels()
dat$vs <- as.factor(dat$vs)
levels(dat$vs)
dat$first_char <- substr(dat$g_cons, 1, 1)
dat$has_hif_yod <- str_detect(dat$stem, 'J')
table(dat$vt)
dim(dat)
table(dat$qsp_sp)
table(dat$lex)
table(dat$law_phase3)
dat_no_jsp_jbc <- dat |> filter(!lex %in% c('JBC[', 'JSP[')) |> droplevels()
dim(dat)
dim(dat_no_jsp_jbc)
head(dat)
table(dat$vs, dat$vt)
