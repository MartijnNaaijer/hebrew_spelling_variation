'4Q365', '4Q96', '4Q111', '4Q109', '11Q5', '11Q6', '11Q7', '11Q8')
length(QSP_SCROLLS)
setwd('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/preprocess_data/data')
library(tidyverse)
library(lme4)
library(brms)
MODEL_FOLDER <- 'C:/Users/geitb/Kopenhagen/KopenhagenResearch/monograph/chapters/NounsAdjectives/models_rstanarm'
EBH_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy", "Joshua",
"Judges", "1_Samuel", "2_Samuel", "1_Kings", "2_Kings")
LBH_BOOKS <- c("Esther", "Daniel", "Ezra", "Nehemiah", "1_Chronicles", "2_Chronicles")
LAW_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy")
QSP_SCROLLS = c('2Q3', '4Q13', '4Q20', '2Q7', '4Q27', '1Q4', '2Q12', '4Q37', '4Q38', '4Q38a', '4Q40', '4Q53',
'1Qisaa', '4Q57', '2Q13', '4Q78', '4Q80', '4Q82', '4Q128', '4Q129', '4Q134', '4Q135', '4Q136',
'4Q137', '4Q138', '4Q139', '4Q140', '4Q141', '4Q142', '4Q143', '4Q144', '4Q158', '4Q364',
'4Q365', '4Q96', '4Q111', '4Q109', '11Q5', '11Q6', '11Q7', '11Q8')
length(QSP_SCROLLS)
setwd('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/preprocess_data/data')
dat <- read.csv('nouns_adjectives.csv', sep='\t')
dat <- read.csv('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/preprocess_data/data/nouns_adjectives.csv', sep='\t')
cwd()
cwd
getwd()
dat <- read.csv('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/data/nouns_adjectives.csv', sep='\t')
dim(dat)
head(dat)
str(dat)
unique(dat$book)
sum(is.na(dat$pattern))
sum(table(dat$pattern))
dat$has_suffix <- dat$has_prs | dat$has_nme
# has_prefix, has_prs, has_nme, lex, book, has_vowel_letter
dat$has_prefix <- as.factor(dat$has_prefix)
dat$has_prsx <- as.factor(dat$has_prs)
dat$has_suffix <- as.factor(dat$has_suffix)
dat$has_nme <- as.factor(dat$has_nme)
dat$lex <- as.factor(dat$lex)
dat$book <- as.factor(dat$book)
dat$has_vowel_letter <- as.factor(dat$has_vowel_letter)
dat$type <- as.factor(dat$type)
dat$lex_type <- paste(dat$lex, dat$type, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
dat$book2 <- dat$book %>% str_replace('1_', '') %>% str_replace('2_', '')
table(dat$book2)
dat$phase <- ifelse(dat$book %in% EBH_BOOKS, 'EBH', ifelse(dat$book %in% LBH_BOOKS, 'LBH', 'NO'))
dat$law_phase <- ifelse(dat$book %in% LAW_BOOKS, 0, ifelse(dat$book %in% EBH_BOOKS, 1,
ifelse(dat$book %in% LBH_BOOKS, 2, 3)))
dat$law_phase <- ifelse(dat$book %in% LAW_BOOKS, 0, ifelse(dat$book %in% EBH_BOOKS, 1,
ifelse(dat$book %in% LBH_BOOKS, 2, 3)))
dat$law_phase <- as.factor(dat$law_phase)
dat$qsp <- ifelse(dat$scroll %in% QSP_SCROLLS, 1, 0)
# Make 2 scrolls of 1Qisaa
dat$scroll <- ifelse(dat$scroll == '1Qisaa' & dat$chapter < 34, '1QisaaI',
ifelse(dat$scroll == '1Qisaa' & dat$chapter > 33, '1QisaaII',
dat$scroll))
dat$scroll <- as.factor(dat$scroll)
str(dat)
dat$type
dat$type <- factor(dat$type, levels = c('last', 'first', 'single'))
levels(dat$type)
mt <- dat %>% filter(scroll == 'MT')
variation_lex_type_list <- list()
for (lex_t in unique(mt$lex_type)) {
lex_type_df <- mt %>% filter(lex_type == lex_t)
lt_vowels <- unique(lex_type_df$has_vowel_letter)
if (length(lt_vowels) > 1) {
variation_lex_type_list[[lex_t]] <- lex_type_df
}
}
mt_var <- do.call('rbind', variation_lex_type_list)
head(mt_var)
levels(mt_var$type)
dim(mt_var)
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
MODEL_FOLDER <- './analysis_nouns_adjectives/output/models'
MODEL <- 'bayes_model_mt_var7.rds'
file_path_mt_var <- file.path(MODEL_FOLDER, MODEL)
mt_var_model <- readRDS(file_path_mt_var)
coef <- fixef(mt_var_model, summary = TRUE)
coef
plot(conditional_effects(mt_var_model, effects = 'has_pronominal_suffix'))
plot(conditional_effects(mt_var_model, effects = 'has_nme'))
plot(conditional_effects(mt_var_model, effects = 'has_prefix'))
plot(conditional_effects(mt_var_model, effects = 'law_phase'))
# make plots to check for convergence
plot(mt_var_model)
ggpredict(mt_var_model, terms = c('law_phase', 'has_nme')) |> plot()
library(ggeffects)
install.packages('ggeffects')
library(ggeffects)
ggpredict(mt_var_model, terms = c('law_phase', 'has_nme')) |> plot()
ggpredict(mt_var_model, terms = c('law_phase', 'has_nme', 'type')) |> plot()
ggpredict(mt_var_model, terms = c('law_phase', 'has_nme', 'type [1]')) |> plot()
ggpredict(mt_var_model, terms = c('law_phase', 'has_nme', 'type ["last"]')) |> plot()
ggpredict(mt_var_model, terms = c('type ["last"]')) |> plot()
ggpredict(mt_var_model, terms = c('type ['last']')) |> plot()
ggpredict(mt_var_model, terms = c("type ['last']")) |> plot()
ggpredict(mt_var_model, terms = c("type")) |> plot()
ggpredict(mt_var_model, terms = c('has_nme', "type ["last"]")) |> plot()
ggpredict(mt_var_model, terms = c('has_nme', "type ['last']")) |> plot()
ggpredict(mt_var_model, terms = c('has_nme', "type ['1']")) |> plot()
ggpredict(mt_var_model, terms = c("type ['last]", 'has_nme')) |> plot()
ggpredict(mt_var_model, terms = c("type ['last']", 'has_nme')) |> plot()
ggpredict(mt_var_model, terms = c("type [last]", 'has_nme')) |> plot()
library(tidyverse)
library(lme4)
library(brms)
MODEL_FOLDER <- 'C:/Users/geitb/Kopenhagen/KopenhagenResearch/monograph/chapters/NounsAdjectives/models_rstanarm'
EBH_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy", "Joshua",
"Judges", "1_Samuel", "2_Samuel", "1_Kings", "2_Kings")
LBH_BOOKS <- c("Esther", "Daniel", "Ezra", "Nehemiah", "1_Chronicles", "2_Chronicles")
LAW_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy")
QSP_SCROLLS = c('2Q3', '4Q13', '4Q20', '2Q7', '4Q27', '1Q4', '2Q12', '4Q37', '4Q38', '4Q38a', '4Q40', '4Q53',
'1Qisaa', '4Q57', '2Q13', '4Q78', '4Q80', '4Q82', '4Q128', '4Q129', '4Q134', '4Q135', '4Q136',
'4Q137', '4Q138', '4Q139', '4Q140', '4Q141', '4Q142', '4Q143', '4Q144', '4Q158', '4Q364',
'4Q365', '4Q96', '4Q111', '4Q109', '11Q5', '11Q6', '11Q7', '11Q8')
length(QSP_SCROLLS)
dat <- read.csv('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/data/nouns_adjectives.csv', sep='\t')
dim(dat)
head(dat)
str(dat)
unique(dat$book)
sum(is.na(dat$pattern))
sum(table(dat$pattern))
dat$has_suffix <- dat$has_prs | dat$has_nme
# has_prefix, has_prs, has_nme, lex, book, has_vowel_letter
dat$has_prefix <- as.factor(dat$has_prefix)
dat$has_prsx <- as.factor(dat$has_prs)
dat$has_suffix <- as.factor(dat$has_suffix)
dat$has_nme <- as.factor(dat$has_nme)
dat$lex <- as.factor(dat$lex)
dat$book <- as.factor(dat$book)
dat$has_vowel_letter <- as.factor(dat$has_vowel_letter)
dat$type <- as.factor(dat$type)
dat$lex_type <- paste(dat$lex, dat$type, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
dat$book2 <- dat$book %>% str_replace('1_', '') %>% str_replace('2_', '')
table(dat$book2)
dat$phase <- ifelse(dat$book %in% EBH_BOOKS, 'EBH', ifelse(dat$book %in% LBH_BOOKS, 'LBH', 'NO'))
dat$law_phase <- ifelse(dat$book %in% LAW_BOOKS, 0, ifelse(dat$book %in% EBH_BOOKS, 1,
ifelse(dat$book %in% LBH_BOOKS, 2, 3)))
dat$law_phase <- as.factor(dat$law_phase)
dat$qsp <- ifelse(dat$scroll %in% QSP_SCROLLS, 1, 0)
# Make 2 scrolls of 1Qisaa
dat$scroll <- ifelse(dat$scroll == '1Qisaa' & dat$chapter < 34, '1QisaaI',
ifelse(dat$scroll == '1Qisaa' & dat$chapter > 33, '1QisaaII',
dat$scroll))
dat$scroll <- as.factor(dat$scroll)
str(dat)
dat$type
dat$type <- factor(dat$type, levels = c('last', 'first', 'single'))
levels(dat$type)
bayes_model_dat <- brm(formula = has_vowel_letter ~
has_pronominal_suffix*type*qsp +
has_nme*type*qsp +
has_prefix*type*qsp +
(has_pronominal_suffix*type + has_nme*type + has_prefix*type | scroll/lex),
prior = set_prior("normal(0, 1)", class = 'Intercept') +
set_prior("normal(0,1)", class = 'b'),
data = dat,
family = bernoulli(link = 'logit'),
warmup = 4000,
iter = 8000,
chains = 4,
cores=4,
control = list(adapt_delta = 0.95),
seed = 123)
bayes_model_dat <- brm(formula = has_vowel_letter ~
has_prs*type*qsp +
has_nme*type*qsp +
has_prefix*type*qsp +
(has_prs*type + has_nme*type + has_prefix*type | scroll/lex),
prior = set_prior("normal(0, 1)", class = 'Intercept') +
set_prior("normal(0,1)", class = 'b'),
data = dat,
family = bernoulli(link = 'logit'),
warmup = 4000,
iter = 8000,
chains = 4,
cores=4,
control = list(adapt_delta = 0.95),
seed = 123)
summary(bayes_model_dat)
ranef(bayes_model_dat)
file_path_dat <- file.path(MODEL_FOLDER, 'bayes_model_dat2.rds')
saveRDS(bayes_model_dat, file = file_path_dat)
library(tidyverse)
library(lme4)
library(brms)
MODEL_FOLDER <- 'C:/Users/geitb/Kopenhagen/KopenhagenResearch/monograph/chapters/NounsAdjectives/models_rstanarm'
EBH_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy", "Joshua",
"Judges", "1_Samuel", "2_Samuel", "1_Kings", "2_Kings")
LBH_BOOKS <- c("Esther", "Daniel", "Ezra", "Nehemiah", "1_Chronicles", "2_Chronicles")
LAW_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy")
QSP_SCROLLS = c('2Q3', '4Q13', '4Q20', '2Q7', '4Q27', '1Q4', '2Q12', '4Q37', '4Q38', '4Q38a', '4Q40', '4Q53',
'1Qisaa', '4Q57', '2Q13', '4Q78', '4Q80', '4Q82', '4Q128', '4Q129', '4Q134', '4Q135', '4Q136',
'4Q137', '4Q138', '4Q139', '4Q140', '4Q141', '4Q142', '4Q143', '4Q144', '4Q158', '4Q364',
'4Q365', '4Q96', '4Q111', '4Q109', '11Q5', '11Q6', '11Q7', '11Q8')
length(QSP_SCROLLS)
dat <- read.csv('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/data/nouns_adjectives.csv', sep='\t')
dim(dat)
head(dat)
str(dat)
unique(dat$book)
sum(is.na(dat$pattern))
sum(table(dat$pattern))
dat$has_suffix <- dat$has_prs | dat$has_nme
# has_prefix, has_prs, has_nme, lex, book, has_vowel_letter
dat$has_prefix <- as.factor(dat$has_prefix)
dat$has_prsx <- as.factor(dat$has_prs)
dat$has_suffix <- as.factor(dat$has_suffix)
dat$has_nme <- as.factor(dat$has_nme)
dat$lex <- as.factor(dat$lex)
dat$book <- as.factor(dat$book)
dat$has_vowel_letter <- as.factor(dat$has_vowel_letter)
dat$type <- as.factor(dat$type)
dat$lex_type <- paste(dat$lex, dat$type, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
dat$book2 <- dat$book %>% str_replace('1_', '') %>% str_replace('2_', '')
table(dat$book2)
dat$phase <- ifelse(dat$book %in% EBH_BOOKS, 'EBH', ifelse(dat$book %in% LBH_BOOKS, 'LBH', 'NO'))
dat$law_phase <- ifelse(dat$book %in% LAW_BOOKS, 0, ifelse(dat$book %in% EBH_BOOKS, 1,
ifelse(dat$book %in% LBH_BOOKS, 2, 3)))
dat$law_phase <- as.factor(dat$law_phase)
dat$qsp <- ifelse(dat$scroll %in% QSP_SCROLLS, 1, 0)
# Make 2 scrolls of 1Qisaa
dat$scroll <- ifelse(dat$scroll == '1Qisaa' & dat$chapter < 34, '1QisaaI',
ifelse(dat$scroll == '1Qisaa' & dat$chapter > 33, '1QisaaII',
dat$scroll))
dat$scroll <- as.factor(dat$scroll)
str(dat)
dat$type
dat$type <- factor(dat$type, levels = c('last', 'first', 'single'))
levels(dat$type)
mt <- dat %>% filter(scroll == 'MT')
variation_lex_type_list <- list()
for (lex_t in unique(mt$lex_type)) {
lex_type_df <- mt %>% filter(lex_type == lex_t)
lt_vowels <- unique(lex_type_df$has_vowel_letter)
if (length(lt_vowels) > 1) {
variation_lex_type_list[[lex_t]] <- lex_type_df
}
}
mt_var <- do.call('rbind', variation_lex_type_list)
head(mt_var)
mean(mt_var$has_vowel_letter)
table(mt_var$has_vowel_letter)
mt_var <- droplevels(mt_var)
length(unique(mt_var$lex))
dim(mt_var)
lex_samples_list <- list()
for (mt_lex in unique(mt_var$lex)) {
lex_df <- mt_var %>% filter(lex == mt_lex)
set.seed(123)
lex_df <- lex_df[sample(nrow(lex_df)),]
nrows = length(lex_df)
set.seed(456)
indices <- sample(1:nrows, 100, replace=TRUE)
lex_df_sampled <- lex_df[indices,]
lex_samples_list[[mt_lex]] <- lex_df_sampled
}
sampled_mt <- do.call('rbind', lex_samples_list)
head(sampled_mt)
dim(sampled_mt)
table(mt_sampled$has_vowel_letter)
table(sampled_mt$has_vowel_letter)
lex_samples_list <- list()
for (bo in unique(mt_var$book)) {
mt_var_book <- mt_var %>% filter(book == bo)
for (mt_lex in unique(mt_var_book$lex)) {
lex_df <- mt_var_book %>% filter(lex == mt_lex)
set.seed(123)
lex_df <- lex_df[sample(nrow(lex_df)),]
nrows = length(lex_df)
set.seed(456)
indices <- sample(1:nrows, 50, replace=TRUE)
lex_df_sampled <- lex_df[indices,]
lex_samples_list[[paste(book, mt_lex)]] <- lex_df_sampled
}
}
lex_samples_list <- list()
for (bo in unique(mt_var$book)) {
mt_var_book <- mt_var %>% filter(book == bo)
for (mt_lex in unique(mt_var_book$lex)) {
lex_df <- mt_var_book %>% filter(lex == mt_lex)
set.seed(123)
lex_df <- lex_df[sample(nrow(lex_df)),]
nrows = length(lex_df)
set.seed(456)
indices <- sample(1:nrows, 50, replace=TRUE)
lex_df_sampled <- lex_df[indices,]
lex_samples_list[[paste(bo, mt_lex)]] <- lex_df_sampled
}
}
sampled_mt <- do.call('rbind', lex_samples_list)
head(sampled_mt)
dim(sampled_mt)
table(sampled_mt$has_vowel_letter)
head(mt_var)
table(mt_var$has_vowel_letter)
mt_var <- droplevels(mt_var)
length(unique(mt_var$lex))
dim(mt_var)
lex_samples_list <- list()
for (bo in unique(mt_var$book)) {
mt_var_book <- mt_var %>% filter(book == bo)
for (mt_lex in unique(mt_var_book$lex)) {
lex_df <- mt_var_book %>% filter(lex == mt_lex)
set.seed(123)
lex_df <- lex_df[sample(nrow(lex_df)),]
nrows = length(lex_df)
set.seed(456)
indices <- sample(1:nrows, 50, replace=TRUE)
lex_df_sampled <- lex_df[indices,]
lex_samples_list[[paste(bo, mt_lex)]] <- lex_df_sampled
}
}
sampled_mt <- do.call('rbind', lex_samples_list)
head(sampled_mt)
dim(sampled_mt)
table(sampled_mt$has_vowel_letter)
tail(sampled_mt)
lex_samples_list <- list()
for (bo in unique(mt_var$book)) {
mt_var_book <- mt_var %>% filter(book == bo)
for (mt_lex in unique(mt_var_book$lex)) {
lex_df <- mt_var_book %>% filter(lex == mt_lex)
set.seed(123)
lex_df <- lex_df[sample(nrow(lex_df)),]
print(head(lex_df))
nrows = length(lex_df)
set.seed(456)
indices <- sample(1:nrows, 50, replace=TRUE)
lex_df_sampled <- lex_df[indices,]
lex_samples_list[[paste(bo, mt_lex)]] <- lex_df_sampled
}
}
lex_samples_list <- list()
for (bo in unique(mt_var$book)) {
mt_var_book <- mt_var %>% filter(book == bo)
for (mt_lex in unique(mt_var_book$lex)) {
lex_df <- mt_var_book %>% filter(lex == mt_lex)
set.seed(123)
lex_df <- lex_df[sample(nrow(lex_df)),]
#print(head(lex_df))
nrows = length(lex_df)
set.seed(456)
indices <- sample(1:nrows, 50, replace=TRUE)
lex_df_sampled <- lex_df[indices,]
print(head(lex_df_sampled))
lex_samples_list[[paste(bo, mt_lex)]] <- lex_df_sampled
}
}
lex_samples_list <- list()
for (bo in unique(mt_var$book)) {
mt_var_book <- mt_var %>% filter(book == bo)
for (mt_lex in unique(mt_var_book$lex)) {
lex_df <- mt_var_book %>% filter(lex == mt_lex)
set.seed(123)
lex_df <- lex_df[sample(nrow(lex_df)),]
rownames(lex_df) <- 1:nrow(lex_df)
#print(head(lex_df))
nrows = length(lex_df)
set.seed(456)
indices <- sample(1:nrows, 50, replace=TRUE)
lex_df_sampled <- lex_df[indices,]
print(head(lex_df_sampled))
lex_samples_list[[paste(bo, mt_lex)]] <- lex_df_sampled
}
}
lex_samples_list <- list()
for (bo in unique(mt_var$book)) {
mt_var_book <- mt_var %>% filter(book == bo)
for (mt_lex in unique(mt_var_book$lex)) {
lex_df <- mt_var_book %>% filter(lex == mt_lex)
set.seed(123)
lex_df <- lex_df[sample(nrow(lex_df)),]
rownames(lex_df) <- 1:nrow(lex_df)
#print(head(lex_df))
nrows = length(lex_df)
set.seed(456)
indices <- sample(1:nrows, 50, replace=TRUE)
print(indices)
lex_df_sampled <- lex_df[indices,]
#print(head(lex_df_sampled))
lex_samples_list[[paste(bo, mt_lex)]] <- lex_df_sampled
}
}
for (bo in unique(mt_var$book)) {
mt_var_book <- mt_var %>% filter(book == bo)
for (mt_lex in unique(mt_var_book$lex)) {
lex_df <- mt_var_book %>% filter(lex == mt_lex)
set.seed(123)
lex_df <- lex_df[sample(nrow(lex_df)),]
rownames(lex_df) <- 1:nrow(lex_df)
#print(head(lex_df))
nrows = length(lex_df)
print(len(nrows))
set.seed(456)
indices <- sample(1:nrows, 50, replace=TRUE)
print(indices)
lex_df_sampled <- lex_df[indices,]
#print(head(lex_df_sampled))
lex_samples_list[[paste(bo, mt_lex)]] <- lex_df_sampled
}
}
for (bo in unique(mt_var$book)) {
mt_var_book <- mt_var %>% filter(book == bo)
for (mt_lex in unique(mt_var_book$lex)) {
lex_df <- mt_var_book %>% filter(lex == mt_lex)
set.seed(123)
lex_df <- lex_df[sample(nrow(lex_df)),]
rownames(lex_df) <- 1:nrow(lex_df)
#print(head(lex_df))
nrows = length(lex_df)
print(dim(nrows))
set.seed(456)
indices <- sample(1:nrows, 50, replace=TRUE)
print(indices)
lex_df_sampled <- lex_df[indices,]
#print(head(lex_df_sampled))
lex_samples_list[[paste(bo, mt_lex)]] <- lex_df_sampled
}
}
for (bo in unique(mt_var$book)) {
mt_var_book <- mt_var %>% filter(book == bo)
for (mt_lex in unique(mt_var_book$lex)) {
lex_df <- mt_var_book %>% filter(lex == mt_lex)
set.seed(123)
lex_df <- lex_df[sample(nrow(lex_df)),]
rownames(lex_df) <- 1:nrow(lex_df)
#print(head(lex_df))
nrows = length(lex_df)
print((nrows))
set.seed(456)
indices <- sample(1:nrows, 50, replace=TRUE)
print(indices)
lex_df_sampled <- lex_df[indices,]
#print(head(lex_df_sampled))
lex_samples_list[[paste(bo, mt_lex)]] <- lex_df_sampled
}
}
for (bo in unique(mt_var$book)) {
mt_var_book <- mt_var %>% filter(book == bo)
for (mt_lex in unique(mt_var_book$lex)) {
lex_df <- mt_var_book %>% filter(lex == mt_lex)
set.seed(123)
lex_df <- lex_df[sample(nrow(lex_df)),]
rownames(lex_df) <- 1:nrow(lex_df)
print(head(lex_df))
#print(head(lex_df))
nrows = length(lex_df)
print((nrows))
set.seed(456)
indices <- sample(1:nrows, 50, replace=TRUE)
print(indices)
lex_df_sampled <- lex_df[indices,]
#print(head(lex_df_sampled))
lex_samples_list[[paste(bo, mt_lex)]] <- lex_df_sampled
}
}
lex_samples_list <- list()
for (bo in unique(mt_var$book)) {
mt_var_book <- mt_var %>% filter(book == bo)
for (mt_lex in unique(mt_var_book$lex)) {
lex_df <- mt_var_book %>% filter(lex == mt_lex)
set.seed(123)
lex_df <- lex_df[sample(nrow(lex_df)),]
rownames(lex_df) <- 1:nrow(lex_df)
#print(head(lex_df))
#print(head(lex_df))
nrows = nrow(lex_df)
print((nrows))
set.seed(456)
indices <- sample(1:nrows, 50, replace=TRUE)
print(indices)
lex_df_sampled <- lex_df[indices,]
#print(head(lex_df_sampled))
lex_samples_list[[paste(bo, mt_lex)]] <- lex_df_sampled
}
}
lex_samples_list <- list()
for (bo in unique(mt_var$book)) {
mt_var_book <- mt_var %>% filter(book == bo)
for (mt_lex in unique(mt_var_book$lex)) {
lex_df <- mt_var_book %>% filter(lex == mt_lex)
set.seed(123)
lex_df <- lex_df[sample(nrow(lex_df)),]
rownames(lex_df) <- 1:nrow(lex_df)
#print(head(lex_df))
#print(head(lex_df))
nrows = nrow(lex_df)
#print((nrows))
set.seed(456)
indices <- sample(1:nrows, 50, replace=TRUE)
#print(indices)
lex_df_sampled <- lex_df[indices,]
#print(head(lex_df_sampled))
lex_samples_list[[paste(bo, mt_lex)]] <- lex_df_sampled
}
}
sampled_mt <- do.call('rbind', lex_samples_list)
head(sampled_mt)
tail(sampled_mt)
dim(sampled_mt)
table(sampled_mt$has_vowel_letter)
no_aff <- sampled_mt %>% filter(has_nme == 0 & has_prs == 0 & has_prefix == 0)
table(no_aff$has_vowel_letter)
table(sampled_mt$has_vowel_letter, mt_sampled$has_prefix)
table(sampled_mt$has_vowel_letter, sampled_mt$has_prefix)
