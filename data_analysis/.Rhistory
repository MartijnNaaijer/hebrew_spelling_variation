row.names=FALSE)
phase_book_df <- single_df |>  distinct(law_phase2, scr_book2)
write.csv(phase_book_df,
'C:/Users/geitb/Dropbox/monograph_orthography/cluster_analysis/phase_book_na_single.csv',
row.names=FALSE)
################################################################################
dim(first_df)
unique(last_df$law_phase2)
dim(last_df)
dim(single_df)
table(single_df$has_suffix, single_df$has_vowel_letter, single_df$law_phase2)
add_lex_vl <- function(df) {
# Add most frequent vowel letter occurring in a lexeme.
last_vl <- as.data.frame.matrix(table(df$lex, df$vowel_letter))
last_vl$V1 <- NULL
max_vowel_idcs <- max.col(last_vl)
last_lex_vl <- data.frame(lex=rownames(last_vl), lex_vl=colnames(last_vl)[max_vowel_idcs])
df <- merge(df, last_lex_vl, by='lex')
df$lex_vl <- as.factor(df$lex_vl)
df$lex_vl <- relevel(df$lex_vl, ref = "W")
df$lex_vl2 <- as.factor(ifelse(df$lex_vl %in% c('W', '>'), 'non-yod', 'yod'))
return(df)
}
last_df <- last_df |> add_lex_vl()
first_df <- first_df |> add_lex_vl()
single_df <- single_df |> add_lex_vl()
head(last_df)
first_df |> filter(lex == '<CN=/')
last_df_mt <- last_df |> filter(scroll == 'MT')
first_df_mt <- first_df |> filter(scroll == 'MT')
single_df_mt <- single_df |> filter(scroll == 'MT')
table(last_df_mt$lex_vl, last_df_mt$has_vowel_letter)
table(first_df_mt$lex_vl, first_df_mt$has_vowel_letter)
table(single_df_mt$lex_vl, single_df_mt$has_vowel_letter)
table(last_df$has_suffix, last_df$has_vowel_letter, last_df$lex_vl)
table(first_df$has_suffix, first_df$has_vowel_letter, first_df$lex_vl)
table(single_df$has_suffix, single_df$has_vowel_letter, single_df$lex_vl)
last_df_w <- last_df |> filter(lex_vl =='W')
table(last_df_w$has_suffix, last_df_w$has_vowel_letter, last_df_w$law_phase2)
last_df_j <- last_df |> filter(lex_vl =='J')
table(last_df_j$has_suffix, last_df_j$has_vowel_letter, last_df_j$law_phase2)
last_df_aleph <- last_df |> filter(lex_vl =='>')
dim(last_df_aleph)
table(last_df$qsp_sp)
prop.table(table(first_df$lex_vl))
first_df_w_mt <- first_df_w |> filter(scroll == 'MT')
table(first_df$lex_vl)
first_df_w <- first_df |> filter(lex_vl =='W')
table(first_df_w$has_suffix, first_df_w$has_vowel_letter, first_df_w$law_phase2)
first_df_j <- first_df |> filter(lex_vl =='J')
table(first_df_j$has_suffix, first_df_j$has_vowel_letter, first_df_j$law_phase2)
first_df_aleph <- first_df |> filter(lex_vl =='>')
dim(first_df_aleph)
unique(first_df_j$lex)
table(last_df_w$has_hloc, last_df_w$law_phase3)
head(first_df_w_mt)
first_df_w_mt <- first_df_w |> filter(scroll == 'MT') |>
filter(law_phase3 == 'MT Pentateuch') |>
droplevels()
dim(first_df_w_mt)
head(first_df_w_mt)
lexemes <- unique(first_df_w_mt$lex)
lexemes
for (lex1 in lexemes) {
lex_df <- first_df_w_mt |> filter(lex == lex1)
print(lex1)
print(table(lex_df$has_prefix, lex_df$has_vowel_letter))
print('')
}
jbl_mt <- first_df |> filter(scroll == 'MT') |> filter(lex == 'JWBL/')
table(last_df_j$lex)
last_df_j <- last_df |> filter(lex_vl =='J') |> droplevels()
table(last_df_j$has_suffix, last_df_j$has_vowel_letter, last_df_j$law_phase2)
last_df_aleph <- last_df |> filter(lex_vl =='>')
dim(last_df_aleph)
table(last_df$qsp_sp)
prop.table(table(first_df$lex_vl))
first_df_w_mt <- first_df_w |> filter(scroll == 'MT')
table(first_df$lex_vl)
table(last_df_j$lex)
sorted(table(last_df_j$lex))
sort(table(last_df_j$lex))
binary_entropy(p)
entropy <- - (p * log(p) + (1 - p) * log(1 - p))
binary_entropy <- function(p) {
entropy <- - (p * log(p) + (1 - p) * log(1 - p))
return(entropy)
}
p <- 0.9  # Predicted probability
binary_entropy(p)
p <- 0.1  # Predicted probability
binary_entropy(p)
p <- 0.1  # Predicted probability
binary_entropy(p)
p <- 0.01  # Predicted probability
binary_entropy(p)
p <- 0.9  # Predicted probability
binary_entropy(p)
p <- 0.001  # Predicted probability
binary_entropy(p)
p <- 0.01  # Predicted probability
binary_entropy(p)
binary_entropy <- function(p) {
entropy <- - (p * log2(p) + (1 - p) * log2(1 - p))
return(entropy)
}
p <- 0.01  # Predicted probability
binary_entropy(p)
p <- 0.1  # Predicted probability
binary_entropy(p)
p <- 0.05  # Predicted probability
binary_entropy(p)
p <- 0.02  # Predicted probability
binary_entropy(p)
p <- 0.01  # Predicted probability
binary_entropy(p)
p <- 0.015  # Predicted probability
binary_entropy(p)
p <- 0.019  # Predicted probability
binary_entropy(p)
p <- 0.015  # Predicted probability
binary_entropy(p)
p <- 0.017  # Predicted probability
binary_entropy(p)
p <- 0.016  # Predicted probability
binary_entropy(p)
p <- 0.0165  # Predicted probability
binary_entropy(p)
p <- 0.0164  # Predicted probability
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
library(ggmcmc)
library(coda)
library(bayestestR) # p_direction
library(binom)
IMAGE_FOLDER <- 'C:/Users/geitb/Dropbox/monograph_orthography/nouns_adjectives/images_nouns_adjectives'
scripts_path <- 'C:/Users/geitb/Dropbox/monograph_orthography/verbs'
functions_path <- file.path(scripts_path, 'functions.R')
config_path <- file.path(scripts_path, 'config.R')
source(functions_path)
source(config_path)
DATASET <- 'nouns_adjectives.csv'
dat <- import_bib_data(DATA_FOLDER, DATASET)
dat <- dat |>
remove_ketiv_qere() |>
add_col_has_suffix() |>
make_book2_column() |>
make_scr_book2_column() |>
make_law_phase_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS) |>
make_law_phase2_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS, QSP_SCROLLS, law_phase2_levels) |>
make_law_phase3_column(QSP_SCROLLS, law_phase3_levels) |>
split_isaiah_scroll() |>
make_factor_columns(factor_columns) |>
droplevels()
str(dat)
dat$qsp_sp <- ifelse(dat$scroll %in% QSP_SCROLLS, 'QSP',
ifelse(dat$scroll == 'MT', 'MT',
ifelse(dat$scroll == 'SP', 'SP', 'Other')))
dat$qsp_sp <- as.factor(dat$qsp_sp)
table(dat$qsp_sp)
colnames(dat)
head(dat)
table(dat$law_phase2)
unique(dat$law_phase2)
text_sizes = theme(
plot.title = element_text(size = 20),
axis.title.x = element_text(size = 16),
axis.text.x = element_text(size = 14),
axis.title.y = element_blank(),
axis.text.y = element_text(size = 20))
dat$type <- factor(dat$type, levels = c('last', 'first', 'single'))
levels(dat$type)
# Merge single and last syllables in new variable type2
dat$type2 <- ifelse(dat$type %in% c('single', 'last'), 'last', 'first')
dat$type2 <- factor(dat$type2, levels = c('last', 'first'))
dat$lex_type <- paste(dat$lex, dat$type2, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
dat$qsp <- as.factor(dat$qsp)
head(dat)
str(dat)
levels(dat$scr_book2)
################################################################################
lex_df <- dat$lex |> unique() |> as.data.frame()
colnames(lex_df) <- c('lex')
head(lex_df)
lex_df$last_char <- lex_df$lex |> str_replace('/', '') |> str_replace_all('=', '') |> str_sub(-1,-1)
lex_df |> filter(last_char == 'N')
variation_lex_type_list <- list()
for (lex_t in unique(dat$lex_type)) {
lex_type_df <- dat %>% filter(lex_type == lex_t)
lt_vowels <- unique(lex_type_df$has_vowel_letter)
if (length(lt_vowels) > 1) {
variation_lex_type_list[[lex_t]] <- lex_type_df
}
}
dat_var <- do.call('rbind', variation_lex_type_list) |> droplevels()
dat_var <- dat_var[order(dat_var$tf_id),]
dim(dat)
str(dat_var)
colnames(dat_var)
last_df <- dat_var |> filter(type == 'last') |> droplevels()
first_df <- dat_var |> filter(type == 'first') |> droplevels()
single_df <- dat_var |> filter(type == 'single') |> droplevels()
dim(single_df)
dim(last_df)
dim(first_df)
#################################################################################
# NEEDED FOR CLUSTERING IN FILE clustering_regression_results.R
phase_book_df <- first_df |>  distinct(law_phase2, scr_book2)
write.csv(phase_book_df,
'C:/Users/geitb/Dropbox/monograph_orthography/cluster_analysis/phase_book_na_first.csv',
row.names=FALSE)
phase_book_df <- last_df |>  distinct(law_phase2, scr_book2)
write.csv(phase_book_df,
'C:/Users/geitb/Dropbox/monograph_orthography/cluster_analysis/phase_book_na_last.csv',
row.names=FALSE)
phase_book_df <- single_df |>  distinct(law_phase2, scr_book2)
write.csv(phase_book_df,
'C:/Users/geitb/Dropbox/monograph_orthography/cluster_analysis/phase_book_na_single.csv',
row.names=FALSE)
################################################################################
dim(first_df)
unique(last_df$law_phase2)
dim(last_df)
dim(single_df)
table(single_df$has_suffix, single_df$has_vowel_letter, single_df$law_phase2)
add_lex_vl <- function(df) {
# Add most frequent vowel letter occurring in a lexeme.
last_vl <- as.data.frame.matrix(table(df$lex, df$vowel_letter))
last_vl$V1 <- NULL
max_vowel_idcs <- max.col(last_vl)
last_lex_vl <- data.frame(lex=rownames(last_vl), lex_vl=colnames(last_vl)[max_vowel_idcs])
df <- merge(df, last_lex_vl, by='lex')
df$lex_vl <- as.factor(df$lex_vl)
df$lex_vl <- relevel(df$lex_vl, ref = "W")
df$lex_vl2 <- as.factor(ifelse(df$lex_vl %in% c('W', '>'), 'non-yod', 'yod'))
return(df)
}
last_df <- last_df |> add_lex_vl()
first_df <- first_df |> add_lex_vl()
single_df <- single_df |> add_lex_vl()
head(last_df)
first_df |> filter(lex == '<CN=/')
last_df_mt <- last_df |> filter(scroll == 'MT')
first_df_mt <- first_df |> filter(scroll == 'MT')
single_df_mt <- single_df |> filter(scroll == 'MT')
table(last_df_mt$lex_vl, last_df_mt$has_vowel_letter)
table(first_df_mt$lex_vl, first_df_mt$has_vowel_letter)
table(single_df_mt$lex_vl, single_df_mt$has_vowel_letter)
table(last_df$has_suffix, last_df$has_vowel_letter, last_df$lex_vl)
table(first_df$has_suffix, first_df$has_vowel_letter, first_df$lex_vl)
table(single_df$has_suffix, single_df$has_vowel_letter, single_df$lex_vl)
last_df_w <- last_df |> filter(lex_vl =='W') |> droplevels()
table(last_df_w$has_suffix, last_df_w$has_vowel_letter, last_df_w$law_phase2)
last_df_j <- last_df |> filter(lex_vl =='J') |> droplevels()
table(last_df_j$has_suffix, last_df_j$has_vowel_letter, last_df_j$law_phase2)
last_df_aleph <- last_df |> filter(lex_vl =='>')
dim(last_df_aleph)
table(last_df$qsp_sp)
prop.table(table(first_df$lex_vl))
first_df_w_mt <- first_df_w |> filter(scroll == 'MT')
table(first_df$lex_vl)
first_df_w <- first_df |> filter(lex_vl =='W')
table(first_df_w$has_suffix, first_df_w$has_vowel_letter, first_df_w$law_phase2)
first_df_j <- first_df |> filter(lex_vl =='J')
table(first_df_j$has_suffix, first_df_j$has_vowel_letter, first_df_j$law_phase2)
first_df_aleph <- first_df |> filter(lex_vl =='>')
dim(first_df_aleph)
unique(first_df_j$lex)
table(last_df_w$has_hloc, last_df_w$law_phase3)
head(first_df_w_mt)
first_df_w_mt <- first_df_w |> filter(scroll == 'MT') |>
filter(law_phase3 == 'MT Pentateuch') |>
droplevels()
dim(first_df_w_mt)
head(first_df_w_mt)
lexemes <- unique(first_df_w_mt$lex)
lexemes
last_df_w
elohim <- last_df_w |> filter(lex == '>LHJM/')
names(elohim)
table(elohim$qsp_sp, elohim$has_vowel_letter)
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
library(ggmcmc)
library(coda)
library(bayestestR) # p_direction
library(binom)
IMAGE_FOLDER <- 'C:/Users/geitb/Dropbox/monograph_orthography/nouns_adjectives/images_nouns_adjectives'
scripts_path <- 'C:/Users/geitb/Dropbox/monograph_orthography/verbs'
functions_path <- file.path(scripts_path, 'functions.R')
config_path <- file.path(scripts_path, 'config.R')
source(functions_path)
source(config_path)
DATASET <- 'nouns_adjectives.csv'
dat <- import_bib_data(DATA_FOLDER, DATASET)
dat <- dat |>
remove_ketiv_qere() |>
add_col_has_suffix() |>
make_book2_column() |>
make_scr_book2_column() |>
make_law_phase_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS) |>
make_law_phase2_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS, QSP_SCROLLS, law_phase2_levels) |>
make_law_phase3_column(QSP_SCROLLS, law_phase3_levels) |>
split_isaiah_scroll() |>
make_factor_columns(factor_columns) |>
droplevels()
str(dat)
dat$qsp_sp <- ifelse(dat$scroll %in% QSP_SCROLLS, 'QSP',
ifelse(dat$scroll == 'MT', 'MT',
ifelse(dat$scroll == 'SP', 'SP', 'Other')))
dat$qsp_sp <- as.factor(dat$qsp_sp)
table(dat$qsp_sp)
colnames(dat)
head(dat)
table(dat$law_phase2)
unique(dat$law_phase2)
text_sizes = theme(
plot.title = element_text(size = 20),
axis.title.x = element_text(size = 16),
axis.text.x = element_text(size = 14),
axis.title.y = element_blank(),
axis.text.y = element_text(size = 20))
dat$type <- factor(dat$type, levels = c('last', 'first', 'single'))
levels(dat$type)
# Merge single and last syllables in new variable type2
dat$type2 <- ifelse(dat$type %in% c('single', 'last'), 'last', 'first')
dat$type2 <- factor(dat$type2, levels = c('last', 'first'))
dat$lex_type <- paste(dat$lex, dat$type2, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
dat$qsp <- as.factor(dat$qsp)
head(dat)
str(dat)
levels(dat$scr_book2)
################################################################################
lex_df <- dat$lex |> unique() |> as.data.frame()
colnames(lex_df) <- c('lex')
head(lex_df)
lex_df$last_char <- lex_df$lex |> str_replace('/', '') |> str_replace_all('=', '') |> str_sub(-1,-1)
lex_df |> filter(last_char == 'N')
variation_lex_type_list <- list()
for (lex_t in unique(dat$lex_type)) {
lex_type_df <- dat %>% filter(lex_type == lex_t)
lt_vowels <- unique(lex_type_df$has_vowel_letter)
if (length(lt_vowels) > 1) {
variation_lex_type_list[[lex_t]] <- lex_type_df
}
}
dat_var <- do.call('rbind', variation_lex_type_list) |> droplevels()
dat_var <- dat_var[order(dat_var$tf_id),]
dim(dat)
str(dat_var)
colnames(dat_var)
last_df <- dat_var |> filter(type == 'last') |> droplevels()
first_df <- dat_var |> filter(type == 'first') |> droplevels()
single_df <- dat_var |> filter(type == 'single') |> droplevels()
dim(single_df)
dim(last_df)
dim(first_df)
#################################################################################
# NEEDED FOR CLUSTERING IN FILE clustering_regression_results.R
phase_book_df <- first_df |>  distinct(law_phase2, scr_book2)
write.csv(phase_book_df,
'C:/Users/geitb/Dropbox/monograph_orthography/cluster_analysis/phase_book_na_first.csv',
row.names=FALSE)
phase_book_df <- last_df |>  distinct(law_phase2, scr_book2)
write.csv(phase_book_df,
'C:/Users/geitb/Dropbox/monograph_orthography/cluster_analysis/phase_book_na_last.csv',
row.names=FALSE)
phase_book_df <- single_df |>  distinct(law_phase2, scr_book2)
write.csv(phase_book_df,
'C:/Users/geitb/Dropbox/monograph_orthography/cluster_analysis/phase_book_na_single.csv',
row.names=FALSE)
################################################################################
dim(first_df)
unique(last_df$law_phase2)
dim(last_df)
dim(single_df)
table(single_df$has_suffix, single_df$has_vowel_letter, single_df$law_phase2)
add_lex_vl <- function(df) {
# Add most frequent vowel letter occurring in a lexeme.
last_vl <- as.data.frame.matrix(table(df$lex, df$vowel_letter))
last_vl$V1 <- NULL
max_vowel_idcs <- max.col(last_vl)
last_lex_vl <- data.frame(lex=rownames(last_vl), lex_vl=colnames(last_vl)[max_vowel_idcs])
df <- merge(df, last_lex_vl, by='lex')
df$lex_vl <- as.factor(df$lex_vl)
df$lex_vl <- relevel(df$lex_vl, ref = "W")
df$lex_vl2 <- as.factor(ifelse(df$lex_vl %in% c('W', '>'), 'non-yod', 'yod'))
return(df)
}
last_df <- last_df |> add_lex_vl()
first_df <- first_df |> add_lex_vl()
single_df <- single_df |> add_lex_vl()
head(last_df)
first_df |> filter(lex == '<CN=/')
last_df_mt <- last_df |> filter(scroll == 'MT')
first_df_mt <- first_df |> filter(scroll == 'MT')
single_df_mt <- single_df |> filter(scroll == 'MT')
table(last_df_mt$lex_vl, last_df_mt$has_vowel_letter)
table(first_df_mt$lex_vl, first_df_mt$has_vowel_letter)
table(single_df_mt$lex_vl, single_df_mt$has_vowel_letter)
table(last_df$has_suffix, last_df$has_vowel_letter, last_df$lex_vl)
table(first_df$has_suffix, first_df$has_vowel_letter, first_df$lex_vl)
table(single_df$has_suffix, single_df$has_vowel_letter, single_df$lex_vl)
last_df_w <- last_df |> filter(lex_vl =='W') |> droplevels()
table(last_df_w$has_suffix, last_df_w$has_vowel_letter, last_df_w$law_phase2)
last_df_j <- last_df |> filter(lex_vl =='J') |> droplevels()
table(last_df_j$has_suffix, last_df_j$has_vowel_letter, last_df_j$law_phase2)
last_df_aleph <- last_df |> filter(lex_vl =='>')
dim(last_df_aleph)
table(last_df$qsp_sp)
prop.table(table(first_df$lex_vl))
first_df_w_mt <- first_df_w |> filter(scroll == 'MT')
elohim <- last_df_w |> filter(lex == '>LHJM/')
names(elohim)
table(elohim$qsp_sp, elohim$has_vowel_letter)
table(first_df$lex_vl)
first_df_w <- first_df |> filter(lex_vl =='W')
table(first_df_w$has_suffix, first_df_w$has_vowel_letter, first_df_w$law_phase2)
first_df_j <- first_df |> filter(lex_vl =='J')
table(first_df_j$has_suffix, first_df_j$has_vowel_letter, first_df_j$law_phase2)
first_df_aleph <- first_df |> filter(lex_vl =='>')
dim(first_df_aleph)
unique(first_df_j$lex)
table(last_df_w$has_hloc, last_df_w$law_phase3)
head(first_df_w_mt)
first_df_w_mt <- first_df_w |> filter(scroll == 'MT') |>
filter(law_phase3 == 'MT Pentateuch') |>
droplevels()
dim(first_df_w_mt)
head(first_df_w_mt)
lexemes <- unique(first_df_w_mt$lex)
lexemes
last_df_aleph
single_df_aleph
single_df_aleph <- single_df |> filter(lex_vl =='>')
single_df_aleph
sort(table(last_df_j$lex))
single_df_aleph
first_df_aleph
dat_var |> filter(vowel_letter == '>')
first_df_aleph
first_df_aleph |> filter(book2 == ¨Genesis)
first_df_aleph |> filter(book2 == 'Genesis')
dat_var |> filter(vowel_letter == '>')
dat_var |> filter(vowel_letter == '>') |> droplevels()
dv_aleph <- dat_var |> filter(vowel_letter == '>') |> droplevels()
dim(dv_aleph)
unique(dv_aleph$lex)
dat_var |> filter(lex == 'R>CJT/' & typ == 'first')
dat_var |> filter(lex == 'R>CJT/' & type == 'first')
dat_var |> filter(lex == 'R>CJT/' & type == 'first') |> filter(has_vowel_letter == 0)
unique(dv_aleph$lex)
dat_var |> filter(lex == 'LV/') |> filter(has_vowel_letter == 1)
dat_var |> filter(lex == 'LV/') |> filter(has_vowel_letter == 0)
unique(dv_aleph$lex)
dat_var |> filter(lex == 'RMH=/') |> filter(has_vowel_letter == 1)
dat_var |> filter(lex == 'RMH=/') |> filter(has_vowel_letter == 0)
unique(dv_aleph$lex)
dat_var |> filter(lex == 'DG/') |> filter(has_vowel_letter == 1)
dat_var |> filter(lex == 'DG/') |> filter(has_vowel_letter == 0)
dat_var |> filter(lex == 'DG/') |> filter(has_vowel_letter == 1)
dat_var |> filter(lex == 'DG/') |> filter(has_vowel_letter == 0)
dat_var |> filter(lex == 'DG/') |> filter(has_vowel_letter == 0) |> tail()
unique(dv_aleph$lex)
dat_var |> filter(lex == 'KBJR/') |> filter(has_vowel_letter == 1)
dat_var |> filter(lex == 'KBJR/' & type == 'first') |> filter(has_vowel_letter == 1)
dat_var |> filter(lex == 'KBJR/' & type == 'first') |> filter(has_vowel_letter == 0) |> tail()
unique(dv_aleph$lex)
dat_var |> filter(lex == 'JTWM/') |> filter(has_vowel_letter == 1)
dat_var |> filter(lex == 'JTWM/' & type == 'first') |> filter(has_vowel_letter == 1)
dat_var |> filter(lex == 'JTWM/') |> filter(has_vowel_letter == 0) |> tail()
dat_var |> filter(lex == 'JTWM/' & type == 'first') |> filter(has_vowel_letter == 0) |> tail()
dat_var |> filter(lex == 'JTWM/' & type == 'first') |> filter(has_vowel_letter == 0) # |> tail()
dat_var |> filter(lex == 'JTWM/' & type == 'last') |> filter(has_vowel_letter == 0)
unique(dv_aleph$lex)
dat_var |> filter(lex == 'NKR/') |> filter(has_vowel_letter == 1)
dat_var |> filter(lex == 'NKR/') |> filter(has_vowel_letter == 0) |> tail()
unique(dv_aleph$lex)
dat_var |> filter(lex == 'BRWC/') |> filter(has_vowel_letter == 1)
dat_var |> filter(lex == 'BRWC/') |> filter(has_vowel_letter == 1) |> tail()
dat_var |> filter(lex == 'BRWC/') |> filter(has_vowel_letter == 0) |> tail()
dat_var |> filter(lex == 'BRWC/') |> filter(has_vowel_letter == 1) |> tail()
dat_var |> filter(lex == 'BRWC/') |> filter(has_vowel_letter == 1) |> tail()
dat_var |> filter(lex == 'BRWC/') |> filter(has_vowel_letter == 0) |> tail()
dat_var |> filter(lex == 'BRWC/') |> filter(has_vowel_letter == 1) |> tail()
dat_var |> filter(lex == 'BRWC/') |> filter(has_vowel_letter == 1) |> tail()
dat_var |> filter(lex == 'BRWC/') |> filter(has_vowel_letter == 0) |> tail(10)
dat_var |> filter(lex == 'BRWC/') |> filter(has_vowel_letter == 1) |> tail(10)
unique(dv_aleph$lex)
dat_var |> filter(lex == 'BWR/') |> filter(has_vowel_letter == 1) |> tail(10)
dat_var |> filter(lex == 'BWR/') |> filter(has_vowel_letter == 1) #|> tail(10)
dat_var |> filter(lex == 'BWR/') |> filter(has_vowel_letter == 1) |> filter(vowel_letter != 'W') #|> tail(10)
dat_var |> filter(lex == 'BWR/') |> filter(has_vowel_letter == 0) |> tail(10)
dat_var |> filter(lex == 'BWR/') |> filter(has_vowel_letter == 1)
dat_var |> filter(lex == 'BWR/') |> filter(has_vowel_letter == 0) |> tail(10)
unique(dv_aleph$lex)
dat_var |> filter(lex == '>JL/') |> filter(has_vowel_letter == 1)
dat_var |> filter(lex == '>JL/') |> filter(has_vowel_letter == 0) |> tail()
dat_var |> filter(lex == '<WR/') |> filter(has_vowel_letter == 1)
unique(dv_aleph$lex)
dat_var |> filter(lex == '>JL/') |> filter(has_vowel_letter == 1)
unique(dv_aleph$lex)
dim(dv_aleph)
unique(dv_aleph$lex)
