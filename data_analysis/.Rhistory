plot(hc)
plot(hc, hang = -1)
biplot(princomp(all_affixes_selected))
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
MODEL_FOLDER <- 'C:/Users/geitb/Kopenhagen/KopenhagenResearch/monograph/chapters/NounsAdjectives/models_rstanarm'
EBH_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy", "Joshua",
"Judges", "1_Samuel", "2_Samuel", "1_Kings", "2_Kings")
LBH_BOOKS <- c("Esther", "Daniel", "Ezra", "Nehemiah", "1_Chronicles", "2_Chronicles")
LAW_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy")
QSP_SCROLLS = c('2Q3', '4Q13', '4Q20', '2Q7', '4Q27', '1Q4', '2Q12', '4Q37', '4Q38', '4Q38a', '4Q40', '4Q53',
'1Qisaa', '4Q57', '2Q13', '4Q78', '4Q80', '4Q82', '4Q128', '4Q129', '4Q134', '4Q135', '4Q136',
'4Q137', '4Q138', '4Q139', '4Q140', '4Q141', '4Q142', '4Q143', '4Q144', '4Q158', '4Q364',
'4Q365', '4Q96', '4Q111', '4Q109', '11Q5', '11Q6', '11Q7', '11Q8')
length(QSP_SCROLLS)
logit2prob <- function(logit){
odds <- exp(logit)
prob <- odds / (1 + odds)
return(prob)
}
dat <- read.csv('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/data/nouns_adjectives.csv', sep='\t')
dim(dat)
head(dat)
str(dat)
unique(dat$book)
sum(is.na(dat$pattern))
sum(table(dat$pattern))
dat$has_suffix <- as.factor(as.numeric(dat$has_prs | dat$has_nme | dat$has_hloc))
# has_prefix, has_prs, has_nme, lex, book, has_vowel_letter
dat$has_prefix <- as.factor(dat$has_prefix)
dat$has_prs <- as.factor(dat$has_prs)
dat$has_nme <- as.factor(dat$has_nme)
dat$has_hloc <- as.factor(dat$has_hloc)
dat$lex <- as.factor(dat$lex)
dat$book <- as.factor(dat$book)
dat$has_vowel_letter <- as.factor(dat$has_vowel_letter)
dat$neigh_vowel_letter <- as.factor(dat$neigh_vowel_letter)
dat$type <- as.factor(dat$type)
dat$book2 <- dat$book %>% str_replace('1_', '') |> str_replace('2_', '')
table(dat$book2)
dat$scr_book2 <- paste(dat$scroll, dat$book2, sep='_')
mt_sp_books <- unique(dat$scr_book2)
mt_sp_books
dat$scr_book2 <- factor(dat$scr_book2, levels = mt_sp_books)
dat$book2 <- as.factor(dat$book2)
dat$phase <- ifelse(dat$book %in% EBH_BOOKS, 'EBH', ifelse(dat$book %in% LBH_BOOKS, 'LBH', 'NO'))
dat$law_phase <- ifelse(dat$book %in% LAW_BOOKS, 0, ifelse(dat$book %in% EBH_BOOKS, 1,
ifelse(dat$book %in% LBH_BOOKS, 2, 3)))
dat$law_phase <- as.factor(dat$law_phase)
dat$qsp <- ifelse(dat$scroll %in% QSP_SCROLLS, 1, 0)
# Make 2 scrolls of 1Qisaa
dat$scroll <- ifelse(dat$scroll == '1Qisaa' & dat$chapter < 34, '1QisaaI',
ifelse(dat$scroll == '1Qisaa' & dat$chapter > 33, '1QisaaII',
dat$scroll))
dat$scroll <- as.factor(dat$scroll)
str(dat)
dat$type
dat$type <- factor(dat$type, levels = c('last', 'first', 'single'))
levels(dat$type)
# Merge single and last syllables in new variable type2
dat$type2 <- ifelse(dat$type %in% c('single', 'last'), 'last', 'first')
dat$type2 <- factor(dat$type2, levels = c('last', 'first'))
dat$lex_type <- paste(dat$lex, dat$type2, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
mt_dss <- dat |> filter(scroll != 'SP')
variation_lex_type_list <- list()
for (lex_t in unique(mt_dss$lex_type)) {
lex_type_df <- mt_dss %>% filter(lex_type == lex_t)
lt_vowels <- unique(lex_type_df$has_vowel_letter)
if (length(lt_vowels) > 1) {
variation_lex_type_list[[lex_t]] <- lex_type_df
}
}
mt_var <- do.call('rbind', variation_lex_type_list)
mt_var <- mt_var[order(mt_var$tf_id),]
head(mt_var)
levels(mt_var$type)
dim(mt_var)
mt_var <- droplevels(mt_var)
head(mt_dss)
formula_mt_merged_types <- has_vowel_letter ~
has_suffix*type2*qsp +
has_prefix*type2*qsp +
(has_suffix + has_prefix | scroll) +
(has_suffix + has_prefix | lex_type)
formula_mt_dss_merged_types <- has_vowel_letter ~
has_suffix*type2*qsp +
has_prefix*type2*qsp +
(has_suffix + has_prefix | scroll) +
(has_suffix + has_prefix | lex_type)
bayes_model_mt_dss_merged_types <- fit_brm_model(mt_var,
formula_mt_dss_merged_types,
4000, 8000, 0.95)
fit_brm_model <- function(data, formula, warmup, iter, adapt_delta) {
trace <- brm(formula = formula,
prior = set_prior("normal(0, 5)", class = "Intercept") +
set_prior("normal(0, 5)", class = "b"),
data = data,
family = bernoulli(link = "logit"),
warmup = warmup,
iter = iter,
chains = 4,
cores=4,
control = list(adapt_delta = adapt_delta),
seed = 123)
return(trace)
}
head(mt_dss)
formula_mt_dss_merged_types <- has_vowel_letter ~
has_suffix*type2*qsp +
has_prefix*type2*qsp +
(has_suffix + has_prefix | scroll) +
(has_suffix + has_prefix | lex_type)
bayes_model_mt_dss_merged_types <- fit_brm_model(mt_var,
formula_mt_dss_merged_types,
4000, 8000, 0.95)
formula_mt_dss_merged_types <- has_vowel_letter ~
has_suffix*type2*qsp +
has_prefix*type2*qsp #+
bayes_model_mt_dss_merged_types <- fit_brm_model(mt_var,
formula_mt_dss_merged_types,
4000, 8000, 0.95)
summary(bayes_model_mt_dss_merged_types)
str(mt_dss)
dat$qsp <- as.factor(dat$qsp)
mt_dss <- dat |> filter(scroll != 'SP')
str(mt_dss)
variation_lex_type_list <- list()
for (lex_t in unique(mt_dss$lex_type)) {
lex_type_df <- mt_dss %>% filter(lex_type == lex_t)
lt_vowels <- unique(lex_type_df$has_vowel_letter)
if (length(lt_vowels) > 1) {
variation_lex_type_list[[lex_t]] <- lex_type_df
}
}
mt_var <- do.call('rbind', variation_lex_type_list)
mt_var <- mt_var[order(mt_var$tf_id),]
head(mt_var)
levels(mt_var$type)
dim(mt_var)
mt_var <- droplevels(mt_var)
str(mt_var)
MODEL_FOLDER <- 'C:/Users/geitb/Kopenhagen/KopenhagenResearch/monograph/chapters/NounsAdjectives/models_rstanarm'
EBH_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy", "Joshua",
"Judges", "1_Samuel", "2_Samuel", "1_Kings", "2_Kings")
LBH_BOOKS <- c("Esther", "Daniel", "Ezra", "Nehemiah", "1_Chronicles", "2_Chronicles")
LAW_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy")
QSP_SCROLLS = c('2Q3', '4Q13', '4Q20', '2Q7', '4Q27', '1Q4', '2Q12', '4Q37', '4Q38', '4Q38a', '4Q40', '4Q53',
'1Qisaa', '4Q57', '2Q13', '4Q78', '4Q80', '4Q82', '4Q128', '4Q129', '4Q134', '4Q135', '4Q136',
'4Q137', '4Q138', '4Q139', '4Q140', '4Q141', '4Q142', '4Q143', '4Q144', '4Q158', '4Q364',
'4Q365', '4Q96', '4Q111', '4Q109', '11Q5', '11Q6', '11Q7', '11Q8')
length(QSP_SCROLLS)
logit2prob <- function(logit){
odds <- exp(logit)
prob <- odds / (1 + odds)
return(prob)
}
dat <- read.csv('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/data/nouns_adjectives.csv', sep='\t')
dim(dat)
head(dat)
str(dat)
unique(dat$book)
sum(is.na(dat$pattern))
sum(table(dat$pattern))
dat$has_suffix <- as.factor(as.numeric(dat$has_prs | dat$has_nme | dat$has_hloc))
# has_prefix, has_prs, has_nme, lex, book, has_vowel_letter
dat$has_prefix <- as.factor(dat$has_prefix)
dat$has_prs <- as.factor(dat$has_prs)
dat$has_nme <- as.factor(dat$has_nme)
dat$has_hloc <- as.factor(dat$has_hloc)
dat$lex <- as.factor(dat$lex)
dat$book <- as.factor(dat$book)
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
MODEL_FOLDER <- 'C:/Users/geitb/Kopenhagen/KopenhagenResearch/monograph/chapters/NounsAdjectives/models_rstanarm'
EBH_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy", "Joshua",
"Judges", "1_Samuel", "2_Samuel", "1_Kings", "2_Kings")
LBH_BOOKS <- c("Esther", "Daniel", "Ezra", "Nehemiah", "1_Chronicles", "2_Chronicles")
LAW_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy")
QSP_SCROLLS = c('2Q3', '4Q13', '4Q20', '2Q7', '4Q27', '1Q4', '2Q12', '4Q37', '4Q38', '4Q38a', '4Q40', '4Q53',
'1Qisaa', '4Q57', '2Q13', '4Q78', '4Q80', '4Q82', '4Q128', '4Q129', '4Q134', '4Q135', '4Q136',
'4Q137', '4Q138', '4Q139', '4Q140', '4Q141', '4Q142', '4Q143', '4Q144', '4Q158', '4Q364',
'4Q365', '4Q96', '4Q111', '4Q109', '11Q5', '11Q6', '11Q7', '11Q8')
length(QSP_SCROLLS)
logit2prob <- function(logit){
odds <- exp(logit)
prob <- odds / (1 + odds)
return(prob)
}
dat <- read.csv('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/data/nouns_adjectives.csv', sep='\t')
dim(dat)
head(dat)
str(dat)
unique(dat$book)
sum(is.na(dat$pattern))
sum(table(dat$pattern))
dat$has_suffix <- as.factor(as.numeric(dat$has_prs | dat$has_nme | dat$has_hloc))
# has_prefix, has_prs, has_nme, lex, book, has_vowel_letter
dat$has_prefix <- as.factor(dat$has_prefix)
dat$has_prs <- as.factor(dat$has_prs)
dat$has_nme <- as.factor(dat$has_nme)
dat$has_hloc <- as.factor(dat$has_hloc)
dat$lex <- as.factor(dat$lex)
dat$book <- as.factor(dat$book)
dat$has_vowel_letter <- as.factor(dat$has_vowel_letter)
dat$neigh_vowel_letter <- as.factor(dat$neigh_vowel_letter)
dat$type <- as.factor(dat$type)
dat$book2 <- dat$book %>% str_replace('1_', '') |> str_replace('2_', '')
table(dat$book2)
dat$scr_book2 <- paste(dat$scroll, dat$book2, sep='_')
mt_sp_books <- unique(dat$scr_book2)
mt_sp_books
dat$scr_book2 <- factor(dat$scr_book2, levels = mt_sp_books)
dat$book2 <- as.factor(dat$book2)
dat$phase <- ifelse(dat$book %in% EBH_BOOKS, 'EBH', ifelse(dat$book %in% LBH_BOOKS, 'LBH', 'NO'))
dat$law_phase <- ifelse(dat$book %in% LAW_BOOKS, 0, ifelse(dat$book %in% EBH_BOOKS, 1,
ifelse(dat$book %in% LBH_BOOKS, 2, 3)))
dat$law_phase <- as.factor(dat$law_phase)
dat$qsp <- ifelse(dat$scroll %in% QSP_SCROLLS, 1, 0)
# Make 2 scrolls of 1Qisaa
dat$scroll <- ifelse(dat$scroll == '1Qisaa' & dat$chapter < 34, '1QisaaI',
ifelse(dat$scroll == '1Qisaa' & dat$chapter > 33, '1QisaaII',
dat$scroll))
dat$scroll <- as.factor(dat$scroll)
str(dat)
dat$type
dat$type <- factor(dat$type, levels = c('last', 'first', 'single'))
levels(dat$type)
# Merge single and last syllables in new variable type2
dat$type2 <- ifelse(dat$type %in% c('single', 'last'), 'last', 'first')
dat$type2 <- factor(dat$type2, levels = c('last', 'first'))
dat$lex_type <- paste(dat$lex, dat$type2, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
dat$qsp <- as.factor(dat$qsp)
mt_dss <- dat |> filter(scroll != 'SP')
str(mt_dss)
variation_lex_type_list <- list()
for (lex_t in unique(mt_dss$lex_type)) {
lex_type_df <- mt_dss %>% filter(lex_type == lex_t)
lt_vowels <- unique(lex_type_df$has_vowel_letter)
if (length(lt_vowels) > 1) {
variation_lex_type_list[[lex_t]] <- lex_type_df
}
}
mt_var <- do.call('rbind', variation_lex_type_list)
mt_var <- mt_var[order(mt_var$tf_id),]
head(mt_var)
levels(mt_var$type)
dim(mt_var)
mt_var <- droplevels(mt_var)
str(mt_var)
fit_brm_model <- function(data, formula, warmup, iter, adapt_delta) {
trace <- brm(formula = formula,
prior = set_prior("normal(0, 5)", class = "Intercept") +
set_prior("normal(0, 5)", class = "b"),
data = data,
family = bernoulli(link = "logit"),
warmup = warmup,
iter = iter,
chains = 4,
cores=4,
control = list(adapt_delta = adapt_delta),
seed = 123)
return(trace)
}
head(mt_dss)
formula_mt_dss_merged_types <- has_vowel_letter ~
has_suffix*type2*qsp +
has_prefix*type2*qsp #+
bayes_model_mt_dss_merged_types <- fit_brm_model(mt_var,
formula_mt_dss_merged_types,
4000, 8000, 0.95)
summary(bayes_model_mt_dss_merged_types)
formula_mt_dss_merged_types <- has_vowel_letter ~
has_suffix*type2*qsp +
has_prefix*type2*qsp +
(has_suffix + has_prefix | scroll) +
(has_suffix + has_prefix | lex_type)
bayes_model_mt_dss_merged_types <- fit_brm_model(mt_var,
formula_mt_dss_merged_types,
4000, 8000, 0.95)
str(mt_dss)
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
MODEL_FOLDER <- 'C:/Users/geitb/Kopenhagen/KopenhagenResearch/monograph/chapters/NounsAdjectives/models_rstanarm'
EBH_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy", "Joshua",
"Judges", "1_Samuel", "2_Samuel", "1_Kings", "2_Kings")
LBH_BOOKS <- c("Esther", "Daniel", "Ezra", "Nehemiah", "1_Chronicles", "2_Chronicles")
LAW_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy")
QSP_SCROLLS = c('2Q3', '4Q13', '4Q20', '2Q7', '4Q27', '1Q4', '2Q12', '4Q37', '4Q38', '4Q38a', '4Q40', '4Q53',
'1Qisaa', '4Q57', '2Q13', '4Q78', '4Q80', '4Q82', '4Q128', '4Q129', '4Q134', '4Q135', '4Q136',
'4Q137', '4Q138', '4Q139', '4Q140', '4Q141', '4Q142', '4Q143', '4Q144', '4Q158', '4Q364',
'4Q365', '4Q96', '4Q111', '4Q109', '11Q5', '11Q6', '11Q7', '11Q8')
length(QSP_SCROLLS)
logit2prob <- function(logit){
odds <- exp(logit)
prob <- odds / (1 + odds)
return(prob)
}
dat <- read.csv('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/data/nouns_adjectives.csv', sep='\t')
dim(dat)
head(dat)
str(dat)
unique(dat$book)
sum(is.na(dat$pattern))
sum(table(dat$pattern))
dat$has_suffix <- as.factor(as.numeric(dat$has_prs | dat$has_nme | dat$has_hloc))
# has_prefix, has_prs, has_nme, lex, book, has_vowel_letter
dat$has_prefix <- as.factor(dat$has_prefix)
dat$has_prs <- as.factor(dat$has_prs)
dat$has_nme <- as.factor(dat$has_nme)
dat$has_hloc <- as.factor(dat$has_hloc)
dat$lex <- as.factor(dat$lex)
dat$book <- as.factor(dat$book)
dat$has_vowel_letter <- as.factor(dat$has_vowel_letter)
dat$neigh_vowel_letter <- as.factor(dat$neigh_vowel_letter)
dat$type <- as.factor(dat$type)
dat$book2 <- dat$book %>% str_replace('1_', '') |> str_replace('2_', '')
table(dat$book2)
dat$scr_book2 <- paste(dat$scroll, dat$book2, sep='_')
mt_sp_books <- unique(dat$scr_book2)
mt_sp_books
dat$scr_book2 <- factor(dat$scr_book2, levels = mt_sp_books)
dat$book2 <- as.factor(dat$book2)
dat$phase <- ifelse(dat$book %in% EBH_BOOKS, 'EBH', ifelse(dat$book %in% LBH_BOOKS, 'LBH', 'NO'))
dat$law_phase <- ifelse(dat$book %in% LAW_BOOKS, 0, ifelse(dat$book %in% EBH_BOOKS, 1,
ifelse(dat$book %in% LBH_BOOKS, 2, 3)))
dat$law_phase <- as.factor(dat$law_phase)
dat$qsp <- ifelse(dat$scroll %in% QSP_SCROLLS, 1, 0)
# Make 2 scrolls of 1Qisaa
dat$scroll <- ifelse(dat$scroll == '1Qisaa' & dat$chapter < 34, '1QisaaI',
ifelse(dat$scroll == '1Qisaa' & dat$chapter > 33, '1QisaaII',
dat$scroll))
dat$scroll <- as.factor(dat$scroll)
str(dat)
dat$type
dat$type <- factor(dat$type, levels = c('last', 'first', 'single'))
levels(dat$type)
# Merge single and last syllables in new variable type2
dat$type2 <- ifelse(dat$type %in% c('single', 'last'), 'last', 'first')
dat$type2 <- factor(dat$type2, levels = c('last', 'first'))
dat$lex_type <- paste(dat$lex, dat$type2, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
dat$qsp <- as.factor(dat$qsp)
mt_dss <- dat |> filter(scroll != 'SP')
str(mt_dss)
variation_lex_type_list <- list()
for (lex_t in unique(mt_dss$lex_type)) {
lex_type_df <- mt_dss %>% filter(lex_type == lex_t)
lt_vowels <- unique(lex_type_df$has_vowel_letter)
if (length(lt_vowels) > 1) {
variation_lex_type_list[[lex_t]] <- lex_type_df
}
}
mt_var <- do.call('rbind', variation_lex_type_list)
mt_var <- mt_var[order(mt_var$tf_id),]
head(mt_var)
levels(mt_var$type)
dim(mt_var)
mt_var <- droplevels(mt_var)
str(mt_var)
fit_brm_model <- function(data, formula, warmup, iter, adapt_delta) {
trace <- brm(formula = formula,
prior = set_prior("normal(0, 5)", class = "Intercept") +
set_prior("normal(0, 5)", class = "b"),
data = data,
family = bernoulli(link = "logit"),
warmup = warmup,
iter = iter,
chains = 4,
cores=4,
control = list(adapt_delta = adapt_delta),
seed = 123)
return(trace)
}
head(mt_dss)
str(mt_dss)
formula_mt_dss_merged_types <- has_vowel_letter ~
has_suffix*type2*qsp +
has_prefix*type2*qsp +
(has_suffix + has_prefix | scr_book2) +
(has_suffix + has_prefix | lex_type)
bayes_model_mt_dss_merged_types <- fit_brm_model(mt_var,
formula_mt_dss_merged_types,
4000, 8000, 0.95)
summary(bayes_model_mt_dss_merged_types)
file_path_mt_var_types <- file.path(MODEL_FOLDER, 'bayes_model_mt_dss_affix_effect_merged_types.rds')
saveRDS(bayes_model_mt_dss_merged_types, file = file_path_mt_var_types)
logit2prob(2.32)
ranef(bayes_model_mt_dss_merged_types)
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
MODEL_FOLDER <- 'C:/Users/geitb/Kopenhagen/KopenhagenResearch/monograph/chapters/NounsAdjectives/models_rstanarm'
EBH_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy", "Joshua",
"Judges", "1_Samuel", "2_Samuel", "1_Kings", "2_Kings")
LBH_BOOKS <- c("Esther", "Daniel", "Ezra", "Nehemiah", "1_Chronicles", "2_Chronicles")
LAW_BOOKS <- c("Genesis", "Exodus", "Leviticus", "Numbers", "Deuteronomy")
QSP_SCROLLS = c('2Q3', '4Q13', '4Q20', '2Q7', '4Q27', '1Q4', '2Q12', '4Q37', '4Q38', '4Q38a', '4Q40', '4Q53',
'1Qisaa', '4Q57', '2Q13', '4Q78', '4Q80', '4Q82', '4Q128', '4Q129', '4Q134', '4Q135', '4Q136',
'4Q137', '4Q138', '4Q139', '4Q140', '4Q141', '4Q142', '4Q143', '4Q144', '4Q158', '4Q364',
'4Q365', '4Q96', '4Q111', '4Q109', '11Q5', '11Q6', '11Q7', '11Q8')
length(QSP_SCROLLS)
logit2prob <- function(logit){
odds <- exp(logit)
prob <- odds / (1 + odds)
return(prob)
}
dat <- read.csv('C:/Users/geitb/Kopenhagen/KopenhagenResearch/scripts_research/hebrew_spelling_variation/data/nouns_adjectives.csv', sep='\t')
dim(dat)
head(dat)
str(dat)
unique(dat$book)
sum(is.na(dat$pattern))
sum(table(dat$pattern))
dat$has_suffix <- as.factor(as.numeric(dat$has_prs | dat$has_nme | dat$has_hloc))
# has_prefix, has_prs, has_nme, lex, book, has_vowel_letter
dat$has_prefix <- as.factor(dat$has_prefix)
dat$has_prs <- as.factor(dat$has_prs)
dat$has_nme <- as.factor(dat$has_nme)
dat$has_hloc <- as.factor(dat$has_hloc)
dat$lex <- as.factor(dat$lex)
dat$book <- as.factor(dat$book)
dat$has_vowel_letter <- as.factor(dat$has_vowel_letter)
dat$neigh_vowel_letter <- as.factor(dat$neigh_vowel_letter)
dat$type <- as.factor(dat$type)
dat$book2 <- dat$book %>% str_replace('1_', '') |> str_replace('2_', '')
table(dat$book2)
# Make 2 scrolls of 1Qisaa
dat$scroll <- ifelse(dat$scroll == '1Qisaa' & dat$chapter < 34, '1QisaaI',
ifelse(dat$scroll == '1Qisaa' & dat$chapter > 33, '1QisaaII',
dat$scroll))
dat$scroll <- as.factor(dat$scroll)
dat$scr_book2 <- paste(dat$scroll, dat$book2, sep='_')
mt_sp_books <- unique(dat$scr_book2)
mt_sp_books
dat$scr_book2 <- factor(dat$scr_book2, levels = mt_sp_books)
unique(dat$scr_book2)
dat$book2 <- as.factor(dat$book2)
dat$phase <- ifelse(dat$book %in% EBH_BOOKS, 'EBH', ifelse(dat$book %in% LBH_BOOKS, 'LBH', 'NO'))
dat$law_phase <- ifelse(dat$book %in% LAW_BOOKS, 0, ifelse(dat$book %in% EBH_BOOKS, 1,
ifelse(dat$book %in% LBH_BOOKS, 2, 3)))
dat$law_phase <- as.factor(dat$law_phase)
dat$qsp <- ifelse(dat$scroll %in% QSP_SCROLLS, 1, 0)
str(dat)
dat$type
dat$type <- factor(dat$type, levels = c('last', 'first', 'single'))
levels(dat$type)
# Merge single and last syllables in new variable type2
dat$type2 <- ifelse(dat$type %in% c('single', 'last'), 'last', 'first')
dat$type2 <- factor(dat$type2, levels = c('last', 'first'))
dat$lex_type <- paste(dat$lex, dat$type2, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
dat$qsp <- as.factor(dat$qsp)
mt_dss <- dat |> filter(scroll != 'SP')
str(mt_dss)
variation_lex_type_list <- list()
for (lex_t in unique(mt_dss$lex_type)) {
lex_type_df <- mt_dss %>% filter(lex_type == lex_t)
lt_vowels <- unique(lex_type_df$has_vowel_letter)
if (length(lt_vowels) > 1) {
variation_lex_type_list[[lex_t]] <- lex_type_df
}
}
mt_var <- do.call('rbind', variation_lex_type_list)
mt_var <- mt_var[order(mt_var$tf_id),]
head(mt_var)
levels(mt_var$type)
dim(mt_var)
mt_var <- droplevels(mt_var)
str(mt_var)
str(mt_dss)
str(mt_var)
fit_brm_model <- function(data, formula, warmup, iter, adapt_delta) {
trace <- brm(formula = formula,
prior = set_prior("normal(0, 5)", class = "Intercept") +
set_prior("normal(0, 5)", class = "b"),
data = data,
family = bernoulli(link = "logit"),
warmup = warmup,
iter = iter,
chains = 4,
cores=4,
control = list(adapt_delta = adapt_delta),
seed = 123)
return(trace)
}
head(mt_dss)
str(mt_dss)
formula_mt_dss_merged_types <- has_vowel_letter ~
has_suffix*type2*qsp +
has_prefix*type2*qsp +
(has_suffix + has_prefix | scr_book2) +
(has_suffix + has_prefix | lex_type)
bayes_model_mt_dss_merged_types <- fit_brm_model(mt_var,
formula_mt_dss_merged_types,
4000, 8000, 0.95)
summary(bayes_model_mt_dss_merged_types)
ranef(bayes_model_mt_dss_merged_types)
file_path_mt_var_types <- file.path(MODEL_FOLDER, 'bayes_model_mt_dss_affix_effect_merged_types.rds')
saveRDS(bayes_model_mt_dss_merged_types, file = file_path_mt_var_types)
