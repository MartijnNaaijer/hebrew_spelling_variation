khn <-first_df_w |> filter(lex == 'KHN/')
dim(khn)
table(khn$qsp_sp)
table(khn$qsp_sp, khn$has_vowel_letter)
khn_oth <- khn |> filter(qsp_sp == 'Other')
table(khn_oth$scr_book2, khn_oth$has_vowel_letter)
khn_oth <- khn |> filter(qsp_sp == 'Other') |> droplevels()
table(khn_oth$scr_book2, khn_oth$has_vowel_letter)
khn_oth |> filter(has_vowel_letter == 1)
khn |> filter(qsp_sp == qsp)
khn |> filter(qsp_sp == 'qsp')
table(khn$qsp_sp, khn$has_vowel_letter)
khn |> filter(qsp_sp == 'QSP')
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
library(ggmcmc)
library(coda)
library(bayestestR) # p_direction
library(binom)
IMAGE_FOLDER <- 'C:/Users/geitb/Dropbox/monograph_orthography/nouns_adjectives/images_nouns_adjectives'
scripts_path <- 'C:/Users/geitb/Dropbox/monograph_orthography/verbs'
functions_path <- file.path(scripts_path, 'functions.R')
config_path <- file.path(scripts_path, 'config.R')
source(functions_path)
source(config_path)
DATASET <- 'nouns_adjectives.csv'
dat <- import_bib_data(DATA_FOLDER, DATASET)
dat <- dat |>
remove_ketiv_qere() |>
add_col_has_suffix() |>
make_book2_column() |>
make_scr_book2_column() |>
make_law_phase_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS) |>
make_law_phase2_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS, QSP_SCROLLS, law_phase2_levels) |>
make_law_phase3_column(QSP_SCROLLS, law_phase3_levels) |>
split_isaiah_scroll() |>
make_factor_columns(factor_columns) |>
droplevels()
# Mistakes in lexeme SP
dat <- dat |> filter(tf_id != 589682) |> filter(tf_id != 595094)
str(dat)
dat$qsp_sp <- ifelse(dat$scroll %in% QSP_SCROLLS, 'QSP',
ifelse(dat$scroll == 'MT', 'MT',
ifelse(dat$scroll == 'SP', 'SP', 'Other')))
dat$qsp_sp <- as.factor(dat$qsp_sp)
table(dat$qsp_sp)
colnames(dat)
head(dat)
table(dat$law_phase2)
unique(dat$law_phase2)
text_sizes = theme(
plot.title = element_text(size = 20),
axis.title.x = element_text(size = 16),
axis.text.x = element_text(size = 14),
axis.title.y = element_blank(),
axis.text.y = element_text(size = 20))
dat$type <- factor(dat$type, levels = c('last', 'first', 'single'))
levels(dat$type)
# Merge single and last syllables in new variable type2
dat$type2 <- ifelse(dat$type %in% c('single', 'last'), 'last', 'first')
dat$type2 <- factor(dat$type2, levels = c('last', 'first'))
dat$lex_type <- paste(dat$lex, dat$type2, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
dat$qsp <- as.factor(dat$qsp)
head(dat)
str(dat)
levels(dat$scr_book2)
################################################################################
lex_df <- dat$lex |> unique() |> as.data.frame()
colnames(lex_df) <- c('lex')
head(lex_df)
lex_df$last_char <- lex_df$lex |> str_replace('/', '') |> str_replace_all('=', '') |> str_sub(-1,-1)
lex_df |> filter(last_char == 'N')
variation_lex_type_list <- list()
for (lex_t in unique(dat$lex_type)) {
lex_type_df <- dat %>% filter(lex_type == lex_t)
lt_vowels <- unique(lex_type_df$has_vowel_letter)
if (length(lt_vowels) > 1) {
variation_lex_type_list[[lex_t]] <- lex_type_df
}
}
dat_var <- do.call('rbind', variation_lex_type_list) |> droplevels()
dat_var <- dat_var[order(dat_var$tf_id),]
dim(dat)
str(dat_var)
colnames(dat_var)
last_df <- dat_var |> filter(type == 'last') |> droplevels()
first_df <- dat_var |> filter(type == 'first') |> droplevels()
single_df <- dat_var |> filter(type == 'single') |> droplevels()
dim(single_df)
dim(last_df)
dim(first_df)
#################################################################################
# NEEDED FOR CLUSTERING IN FILE clustering_regression_results.R
phase_book_df <- first_df |>  distinct(law_phase2, scr_book2)
write.csv(phase_book_df,
'C:/Users/geitb/Dropbox/monograph_orthography/cluster_analysis/phase_book_na_first.csv',
row.names=FALSE)
phase_book_df <- last_df |>  distinct(law_phase2, scr_book2)
write.csv(phase_book_df,
'C:/Users/geitb/Dropbox/monograph_orthography/cluster_analysis/phase_book_na_last.csv',
row.names=FALSE)
phase_book_df <- single_df |>  distinct(law_phase2, scr_book2)
write.csv(phase_book_df,
'C:/Users/geitb/Dropbox/monograph_orthography/cluster_analysis/phase_book_na_single.csv',
row.names=FALSE)
################################################################################
dim(first_df)
unique(last_df$law_phase2)
dim(last_df)
dim(single_df)
table(single_df$has_suffix, single_df$has_vowel_letter, single_df$law_phase2)
add_lex_vl <- function(df) {
# Add most frequent vowel letter occurring in a lexeme.
last_vl <- as.data.frame.matrix(table(df$lex, df$vowel_letter))
last_vl$V1 <- NULL
max_vowel_idcs <- max.col(last_vl)
last_lex_vl <- data.frame(lex=rownames(last_vl), lex_vl=colnames(last_vl)[max_vowel_idcs])
df <- merge(df, last_lex_vl, by='lex')
df$lex_vl <- as.factor(df$lex_vl)
df$lex_vl <- relevel(df$lex_vl, ref = "W")
df$lex_vl2 <- as.factor(ifelse(df$lex_vl %in% c('W', '>'), 'non-yod', 'yod'))
return(df)
}
last_df <- last_df |> add_lex_vl()
first_df <- first_df |> add_lex_vl()
single_df <- single_df |> add_lex_vl()
head(last_df)
first_df |> filter(lex == '<CN=/')
last_df_mt <- last_df |> filter(scroll == 'MT')
first_df_mt <- first_df |> filter(scroll == 'MT')
single_df_mt <- single_df |> filter(scroll == 'MT')
table(last_df_mt$lex_vl, last_df_mt$has_vowel_letter)
table(first_df_mt$lex_vl, first_df_mt$has_vowel_letter)
table(single_df_mt$lex_vl, single_df_mt$has_vowel_letter)
table(last_df$has_suffix, last_df$has_vowel_letter, last_df$lex_vl)
table(first_df$has_suffix, first_df$has_vowel_letter, first_df$lex_vl)
table(single_df$has_suffix, single_df$has_vowel_letter, single_df$lex_vl)
last_df_w <- last_df |> filter(lex_vl =='W') |> droplevels()
table(last_df_w$has_suffix, last_df_w$has_vowel_letter, last_df_w$law_phase2)
last_df_j <- last_df |> filter(lex_vl =='J') |> droplevels()
table(last_df_j$has_suffix, last_df_j$has_vowel_letter, last_df_j$law_phase2)
last_df_aleph <- last_df |> filter(lex_vl =='>')
dim(last_df_aleph)
table(last_df$qsp_sp)
prop.table(table(first_df$lex_vl))
single_df_w <- single_df |> filter(lex_vl =='W') |> droplevels()
single_df_j <- single_df |> filter(lex_vl =='J') |> droplevels()
dim(single_df_w)
sort(table(single_df_w$lex))
elohim <- last_df_w |> filter(lex == '>LHJM/')
table(elohim$qsp_sp, elohim$has_vowel_letter)
gevul <- last_df_w |> filter(lex == 'MQWM/') |> droplevels()
table(gevul$qsp_sp, gevul$has_vowel_letter)
table(gevul$scr_book2, gevul$has_vowel_letter)
last_df_w |> filter(lex == 'MQWM/') |> filter(scroll == 'MT') |>
filter(has_vowel_letter == 1) |> filter(book2 == 'Genesis') |>
filter(has_prs == 1)
last_df_w |> filter(lex == 'MQWM/') |> filter(qsp_sp == 'Other') |>
filter(has_vowel_letter == 0)
last_df_w |> filter(lex == 'MQWM/') |> filter(qsp_sp == 'Other') |>
filter(has_vowel_letter == 1) |> tail(10)
gevul <- last_df_w |> filter(lex == 'GBWL/') |> droplevels()
table(gevul$qsp_sp, gevul$has_vowel_letter)
table(gevul$scr_book2, gevul$has_vowel_letter)
last_df_w |> filter(lex == 'GBWL/') |> filter(scroll == 'MT') |>
filter(has_vowel_letter == 0) |> filter(book2 == 'Deuteronomy')
last_df_w |> filter(lex == 'GBWL/') |> filter(qsp_sp == 'Other') |>
filter(has_vowel_letter == 0)
table(first_df$lex_vl)
first_df_w <- first_df |> filter(lex_vl =='W') |> droplevels()
table(first_df_w$has_suffix, first_df_w$has_vowel_letter, first_df_w$law_phase2)
first_df_j <- first_df |> filter(lex_vl =='J') |> droplevels()
table(first_df_j$has_suffix, first_df_j$has_vowel_letter, first_df_j$law_phase2)
first_df_aleph <- first_df |> filter(lex_vl =='>') |> droplevels()
dim(first_df_aleph)
unique(first_df_j$lex)
table(last_df_w$has_hloc, last_df_w$law_phase3)
head(first_df_w_mt)
first_df_w_mt <- first_df_w |> filter(scroll == 'MT') |>
filter(law_phase3 == 'MT Pentateuch') |>
droplevels()
dim(first_df_w_mt)
head(first_df_w_mt)
sort(unique(first_df_w$lex))
first_df_w |> filter(lex == 'QDC/' & has_vowel_letter == 1 & scroll != 'MT')
khn <- first_df_w |> filter(lex == 'KHN/')
khn <- first_df_w |> filter(lex == 'XDC=/')
dim(khn)
table(khn$qsp_sp, khn$has_vowel_letter)
khn_oth <- khn |> filter(qsp_sp == 'Other') |> droplevels()
table(khn_oth$scr_book2, khn_oth$has_vowel_letter)
khn_oth |> filter(has_vowel_letter == 1)
khn_oth |> filter(scroll == 4Q51)
khn_oth |> filter(scroll == '4Q51')
khn |> filter(qsp_sp == 'QSP')
table(khn$qsp_sp, khn$has_vowel_letter)
khn <- first_df_w |> filter(lex == 'KWKB/')
dim(khn)
table(khn$qsp_sp, khn$has_vowel_letter)
khn_oth <- khn |> filter(qsp_sp == 'Other') |> droplevels()
table(khn_oth$scr_book2, khn_oth$has_vowel_letter)
khn_oth |> filter(has_vowel_letter == 1)
khn_oth |> filter(has_vowel_letter == 0)
khn <- first_df_w |> filter(lex == 'KWKB/')
dim(khn)
table(khn$qsp_sp, khn$has_vowel_letter)
khn |> filter(scroll == 'MT' & has_vowel_letter == 0)
khn_oth <- khn |> filter(qsp_sp == 'Other') |> droplevels()
table(khn_oth$scr_book2, khn_oth$has_vowel_letter)
khn_oth |> filter(has_vowel_letter == 0)
khn_oth |> filter(has_vowel_letter == 0)
khn_oth
table(khn$qsp_sp, khn$has_vowel_letter)
khn |> filter(qsp_sp == 'QSP')
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
library(ggmcmc)
library(coda)
library(bayestestR) # p_direction
library(binom)
IMAGE_FOLDER <- 'C:/Users/geitb/Dropbox/monograph_orthography/nouns_adjectives/images_nouns_adjectives'
scripts_path <- 'C:/Users/geitb/Dropbox/monograph_orthography/verbs'
functions_path <- file.path(scripts_path, 'functions.R')
config_path <- file.path(scripts_path, 'config.R')
source(functions_path)
source(config_path)
DATASET <- 'nouns_adjectives.csv'
dat <- import_bib_data(DATA_FOLDER, DATASET)
dat <- dat |>
remove_ketiv_qere() |>
add_col_has_suffix() |>
make_book2_column() |>
make_scr_book2_column() |>
make_law_phase_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS) |>
make_law_phase2_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS, QSP_SCROLLS, law_phase2_levels) |>
make_law_phase3_column(QSP_SCROLLS, law_phase3_levels) |>
split_isaiah_scroll() |>
make_factor_columns(factor_columns) |>
droplevels()
# Mistakes in lexeme SP, 1912384 is suspect case in 1QIsaa
dat <- dat |> filter(tf_id != 589682) |> filter(tf_id != 595094) |> filter(tf_id != 1912384)
str(dat)
dat$qsp_sp <- ifelse(dat$scroll %in% QSP_SCROLLS, 'QSP',
ifelse(dat$scroll == 'MT', 'MT',
ifelse(dat$scroll == 'SP', 'SP', 'Other')))
dat$qsp_sp <- as.factor(dat$qsp_sp)
table(dat$qsp_sp)
colnames(dat)
head(dat)
table(dat$law_phase2)
unique(dat$law_phase2)
text_sizes = theme(
plot.title = element_text(size = 20),
axis.title.x = element_text(size = 16),
axis.text.x = element_text(size = 14),
axis.title.y = element_blank(),
axis.text.y = element_text(size = 20))
dat$type <- factor(dat$type, levels = c('last', 'first', 'single'))
levels(dat$type)
# Merge single and last syllables in new variable type2
dat$type2 <- ifelse(dat$type %in% c('single', 'last'), 'last', 'first')
dat$type2 <- factor(dat$type2, levels = c('last', 'first'))
dat$lex_type <- paste(dat$lex, dat$type2, sep='_')
dat$lex_type <- as.factor(dat$lex_type)
dat$qsp <- as.factor(dat$qsp)
head(dat)
str(dat)
levels(dat$scr_book2)
################################################################################
lex_df <- dat$lex |> unique() |> as.data.frame()
colnames(lex_df) <- c('lex')
head(lex_df)
lex_df$last_char <- lex_df$lex |> str_replace('/', '') |> str_replace_all('=', '') |> str_sub(-1,-1)
lex_df |> filter(last_char == 'N')
variation_lex_type_list <- list()
for (lex_t in unique(dat$lex_type)) {
lex_type_df <- dat %>% filter(lex_type == lex_t)
lt_vowels <- unique(lex_type_df$has_vowel_letter)
if (length(lt_vowels) > 1) {
variation_lex_type_list[[lex_t]] <- lex_type_df
}
}
dat_var <- do.call('rbind', variation_lex_type_list) |> droplevels()
dat_var <- dat_var[order(dat_var$tf_id),]
dim(dat)
str(dat_var)
colnames(dat_var)
last_df <- dat_var |> filter(type == 'last') |> droplevels()
first_df <- dat_var |> filter(type == 'first') |> droplevels()
single_df <- dat_var |> filter(type == 'single') |> droplevels()
dim(single_df)
dim(last_df)
dim(first_df)
#################################################################################
# NEEDED FOR CLUSTERING IN FILE clustering_regression_results.R
phase_book_df <- first_df |>  distinct(law_phase2, scr_book2)
write.csv(phase_book_df,
'C:/Users/geitb/Dropbox/monograph_orthography/cluster_analysis/phase_book_na_first.csv',
row.names=FALSE)
phase_book_df <- last_df |>  distinct(law_phase2, scr_book2)
write.csv(phase_book_df,
'C:/Users/geitb/Dropbox/monograph_orthography/cluster_analysis/phase_book_na_last.csv',
row.names=FALSE)
phase_book_df <- single_df |>  distinct(law_phase2, scr_book2)
write.csv(phase_book_df,
'C:/Users/geitb/Dropbox/monograph_orthography/cluster_analysis/phase_book_na_single.csv',
row.names=FALSE)
################################################################################
dim(first_df)
unique(last_df$law_phase2)
dim(last_df)
dim(single_df)
table(single_df$has_suffix, single_df$has_vowel_letter, single_df$law_phase2)
add_lex_vl <- function(df) {
# Add most frequent vowel letter occurring in a lexeme.
last_vl <- as.data.frame.matrix(table(df$lex, df$vowel_letter))
last_vl$V1 <- NULL
max_vowel_idcs <- max.col(last_vl)
last_lex_vl <- data.frame(lex=rownames(last_vl), lex_vl=colnames(last_vl)[max_vowel_idcs])
df <- merge(df, last_lex_vl, by='lex')
df$lex_vl <- as.factor(df$lex_vl)
df$lex_vl <- relevel(df$lex_vl, ref = "W")
df$lex_vl2 <- as.factor(ifelse(df$lex_vl %in% c('W', '>'), 'non-yod', 'yod'))
return(df)
}
last_df <- last_df |> add_lex_vl()
first_df <- first_df |> add_lex_vl()
single_df <- single_df |> add_lex_vl()
head(last_df)
first_df |> filter(lex == '<CN=/')
last_df_mt <- last_df |> filter(scroll == 'MT')
first_df_mt <- first_df |> filter(scroll == 'MT')
single_df_mt <- single_df |> filter(scroll == 'MT')
table(last_df_mt$lex_vl, last_df_mt$has_vowel_letter)
table(first_df_mt$lex_vl, first_df_mt$has_vowel_letter)
table(single_df_mt$lex_vl, single_df_mt$has_vowel_letter)
table(last_df$has_suffix, last_df$has_vowel_letter, last_df$lex_vl)
table(first_df$has_suffix, first_df$has_vowel_letter, first_df$lex_vl)
table(single_df$has_suffix, single_df$has_vowel_letter, single_df$lex_vl)
last_df_w <- last_df |> filter(lex_vl =='W') |> droplevels()
table(last_df_w$has_suffix, last_df_w$has_vowel_letter, last_df_w$law_phase2)
last_df_j <- last_df |> filter(lex_vl =='J') |> droplevels()
table(last_df_j$has_suffix, last_df_j$has_vowel_letter, last_df_j$law_phase2)
last_df_aleph <- last_df |> filter(lex_vl =='>')
dim(last_df_aleph)
table(last_df$qsp_sp)
prop.table(table(first_df$lex_vl))
single_df_w <- single_df |> filter(lex_vl =='W') |> droplevels()
single_df_j <- single_df |> filter(lex_vl =='J') |> droplevels()
dim(single_df_w)
sort(table(single_df_w$lex))
elohim <- last_df_w |> filter(lex == '>LHJM/')
table(elohim$qsp_sp, elohim$has_vowel_letter)
gevul <- last_df_w |> filter(lex == 'MQWM/') |> droplevels()
table(gevul$qsp_sp, gevul$has_vowel_letter)
table(gevul$scr_book2, gevul$has_vowel_letter)
last_df_w |> filter(lex == 'MQWM/') |> filter(scroll == 'MT') |>
filter(has_vowel_letter == 1) |> filter(book2 == 'Genesis') |>
filter(has_prs == 1)
last_df_w |> filter(lex == 'MQWM/') |> filter(qsp_sp == 'Other') |>
filter(has_vowel_letter == 0)
last_df_w |> filter(lex == 'MQWM/') |> filter(qsp_sp == 'Other') |>
filter(has_vowel_letter == 1) |> tail(10)
gevul <- last_df_w |> filter(lex == 'GBWL/') |> droplevels()
table(gevul$qsp_sp, gevul$has_vowel_letter)
table(gevul$scr_book2, gevul$has_vowel_letter)
last_df_w |> filter(lex == 'GBWL/') |> filter(scroll == 'MT') |>
filter(has_vowel_letter == 0) |> filter(book2 == 'Deuteronomy')
last_df_w |> filter(lex == 'GBWL/') |> filter(qsp_sp == 'Other') |>
filter(has_vowel_letter == 0)
table(first_df$lex_vl)
first_df_w <- first_df |> filter(lex_vl =='W') |> droplevels()
table(first_df_w$has_suffix, first_df_w$has_vowel_letter, first_df_w$law_phase2)
first_df_j <- first_df |> filter(lex_vl =='J') |> droplevels()
table(first_df_j$has_suffix, first_df_j$has_vowel_letter, first_df_j$law_phase2)
first_df_aleph <- first_df |> filter(lex_vl =='>') |> droplevels()
dim(first_df_aleph)
unique(first_df_j$lex)
table(last_df_w$has_hloc, last_df_w$law_phase3)
head(first_df_w_mt)
first_df_w_mt <- first_df_w |> filter(scroll == 'MT') |>
filter(law_phase3 == 'MT Pentateuch') |>
droplevels()
dim(first_df_w_mt)
head(first_df_w_mt)
sort(unique(first_df_w$lex))
first_df_w |> filter(lex == 'QDC/' & has_vowel_letter == 1 & scroll != 'MT')
khn <- first_df_w |> filter(lex == 'KWKB/')
dim(khn)
khn |> filter(scroll == 'MT' & has_vowel_letter == 0)
table(khn$qsp_sp, khn$has_vowel_letter)
khn_oth <- khn |> filter(qsp_sp == 'Other') |> droplevels()
table(khn_oth$scr_book2, khn_oth$has_vowel_letter)
khn_oth |> filter(has_vowel_letter == 0)
khn_oth |> filter(scroll == '4Q51')
khn_oth
khn |> filter(qsp_sp == 'QSP')
lexemes <- unique(first_df_w_mt$lex)
lexemes
for (lex1 in lexemes) {
lex_df <- first_df_w_mt |> filter(lex == lex1)
print(lex1)
print(table(lex_df$has_prefix, lex_df$has_vowel_letter))
print('')
}
jbl_mt <- first_df |> filter(scroll == 'MT') |> filter(lex == 'JWBL/')
table(jbl_mt$has_prefix, jbl_mt$has_vowel_letter, jbl_mt$law_phase3)
sort(table(last_df_w$lex))
sort(table(first_df_j$lex))
first_df_j |> filter(lex == 'KTNT/' & has_vowel_letter == 1)
nabi <- last_df_j |> filter(lex == 'NBJ>/') |> droplevels()
table(nabi$has_vowel_letter)
table(nabi$qsp_sp, nabi$has_vowel_letter)
table(nabi$law_phase3, nabi$has_vowel_letter)
nabi |> filter(law_phase3 == 'MT Pentateuch')
nabi |> filter(law_phase3 == 'SP')
nabi_def <- nabi |> filter(has_vowel_letter == 0) |> droplevels()
table(nabi$scr_book2, nabi$has_vowel_letter)
table(nabi_def$scr_book2)
nabi_def
nabi_mt_jer <- nabi |> filter(scr_book2 == 'MT_Jeremiah')
table(nabi_mt_jer$has_suffix, nabi_mt_jer$has_vowel_letter)
nabi_mt_jer
table(nabi_mt_jer$g_cons)
nabi_mt_jer
nabi_mt_jer |> filter(g_cons == 'NBJ>M')
nabi_mt_jer |> filter(g_cons == 'NBJ>J')
table(nabi$has_suffix, nabi$has_vowel_letter)
nabi |> filter(scr_book2 == 'MT_Kings' & has_vowel_letter == 0)
nabi_def |> filter(scr_book2 != 'MT_Jeremiah')
table(nabi$scr_book2, nabi$has_vowel_letter)
table(nabi$scr_book2, nabi$g_cons)
nasi <- last_df_j |> filter(lex == 'GBJ</') |> droplevels()
table(nasi$has_vowel_letter)
# LAST SYLL SUFFIX EFFECT OF DIFFERENT SUFFIXES AND VOWEL LETTERS
# VISUALIZATIONS ARE MADE IN FILE visualizations_different_suffixes_prefixes.R
first_df$nme <- first_df$nme |> as.factor()
first_df$prs <- first_df$prs |> as.factor()
first_df$prefix <- first_df$prefix |> as.factor()
last_df$nme <- last_df$nme |> as.factor()
last_df$prs <- last_df$prs |> as.factor()
last_df$prefix <- last_df$prefix |> as.factor()
levels(last_df$nme)
levels(last_df$prs)
levels(last_df$prefix)
table(last_df$nme)
table(last_df$nme, last_df$nu)
# disambiguate fem T singular and plural markers
last_df$nme2 <- ifelse((last_df$nme == 'T' & last_df$nu == 'sg'), 'T_sg',
ifelse((last_df$nme == 'T' & last_df$nu == 'pl'), 'T_pl',
as.character(last_df$nme))) |> as.factor()
levels(last_df$nme2)
table(last_df$nme, last_df$nme2)
last_mt_y <- last_df |> filter(scroll == 'MT') |> filter(lex_vl == 'J') |> droplevels()
last_mt_w <- last_df |> filter(scroll == 'MT') |> filter(lex_vl == 'W') |> droplevels()
dim(last_mt_y)
dim(last_mt_w)
# ONLY UNIQUE W WORDS
variation_lex_type_list <- list()
for (lex_t in unique(last_mt_w$lex_type)) {
lex_type_df <- last_mt_w %>% filter(lex_type == lex_t)
lt_vowels <- unique(lex_type_df$has_vowel_letter)
if (length(lt_vowels) > 1) {
variation_lex_type_list[[lex_t]] <- lex_type_df
}
}
last_mt_w_var <- do.call('rbind', variation_lex_type_list) |> droplevels()
last_mt_w_var <- last_mt_w_var[order(last_mt_w_var$tf_id),]
dim(last_mt_w_var)
head(last_mt_w_var)
table(last_mt_w$nme2, last_mt_w$law_phase3)
# IMPORTANT FOR VIISUALIZATIONS: WHICH SUFFIXES OCCUR IN SPECIFIC GROUP
table(last_mt_w$prs, last_mt_w$law_phase3)
library(tidyverse)
library(brms)
library(bayesplot)
library(tidybayes)
library(ggeffects)
library(bayestestR) # p_direction
library(binom)
IMAGE_FOLDER <- 'C:/Users/geitb/Dropbox/monograph_orthography/verbs/images_infa'
scripts_path <- 'C:/Users/geitb/Dropbox/monograph_orthography/verbs'
functions_path <- file.path(scripts_path, 'functions.R')
config_path <- file.path(scripts_path, 'config.R')
source(functions_path)
source(config_path)
DATASET <- 'infa_qal.csv'
dat <- import_bib_data(DATA_FOLDER, DATASET)
dat <- dat |>
remove_ketiv_qere() |>
add_col_has_suffix() |>
make_book2_column() |>
make_scr_book2_column() |>
make_law_phase_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS) |>
make_law_phase2_column(LAW_BOOKS, EBH_BOOKS, LBH_BOOKS, QSP_SCROLLS, law_phase2_levels) |>
make_law_phase3_column(QSP_SCROLLS, law_phase3_levels) |>
split_isaiah_scroll() |>
make_factor_columns(factor_columns) |>
droplevels()
str(dat)
dat[dat$tf_id == 2086635]
dat[dat$tf_id == 2086635,]
# Correct defective to full spelling
dat$has_vowel_letter[dat$tf_id == 2086635] <- 1
dat[dat$tf_id == 2086635,]
